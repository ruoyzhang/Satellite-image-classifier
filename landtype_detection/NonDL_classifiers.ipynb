{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classifier for Satellite Images Using Non Deep Learning Methods\n",
    "\n",
    "This notebook demonstrates how we construct an image classifier using non deep learning methods.\n",
    "\n",
    "More specifically, it will cover the following topics in order:\n",
    "\n",
    "## Agenda\n",
    "####    1. Data Preparation: converting image data into vector form\n",
    "####    2. Vanilla Random Forest as a benchmark\n",
    "####    3. Data Augmentation to deal with class inbalance\n",
    "####    4. Random Forest with augmented data\n",
    "####    5. XGBoost (with vanilla data?)\n",
    "####    6. Performance comparison with CNN using pretrained InceptionV3\n",
    "####    7. Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preparation: converting image data into vector form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from custom_dset_new import train_val_test_split\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/Users/ruoyangzhang/Documents/PythonWorkingDirectory/Assignment_data/images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data, test_data = train_val_test_split(data_dir, train_split=0.8, val_split=0.2, test_split = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_train_dirs = [dir for dir in sorted(list(train_data.keys())) if os.path.split(dir)[-1] != '.DS_Store']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_vector(img_dir):\n",
    "    img = cv2.imread(img_dir)\n",
    "    b, g, r = cv2.split(img)\n",
    "    rgb_img = cv2.merge([r, g, b])\n",
    "    rgb_img.shape = (1, 28*28*3)\n",
    "    return(rgb_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 259200/259200 [02:41<00:00, 1602.37it/s]\n"
     ]
    }
   ],
   "source": [
    "input_images = np.array([convert_to_vector(dir) for dir in tqdm(ordered_train_dirs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_images.shape = (input_images.shape[0], input_images.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array([train_data[dir] for dir in ordered_train_dirs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we make test data into np.arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_test_dirs = [dir for dir in sorted(list(val_data.keys())) if os.path.split(dir)[-1] != '.DS_Store']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64800/64800 [00:36<00:00, 1768.60it/s]\n"
     ]
    }
   ],
   "source": [
    "test_images = np.array([convert_to_vector(dir) for dir in tqdm(ordered_test_dirs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images.shape = (test_images.shape[0], test_images.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = np.array([val_data[dir] for dir in ordered_test_dirs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Vanilla Random Forest as a benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn import metrics\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, n_jobs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=5,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(input_images,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9661574074074074\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(test_labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[24130,     0,     0,     0,     0,     0],\n",
       "       [   13, 11355,     1,     4,     0,    69],\n",
       "       [   94,    30,  1310,    35,   138,    49],\n",
       "       [    1,    56,     0, 14065,    21,   503],\n",
       "       [   18,     0,    50,     2,  2856,     0],\n",
       "       [   21,   625,     1,   461,     1,  8891]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(test_labels, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balance  , water: 0.3724, trees: 0.1766, road: 0.0256, barren_land: 0.2260, building: 0.0452, grassland: 0.1543\n",
      "---------------\n",
      "precision, water: 0.9939, trees: 0.9411, road: 0.9618, barren_land: 0.9655, building: 0.9469, grassland: 0.9347\n",
      "---------------\n",
      "recall   , water: 1.0000, trees: 0.9924, road: 0.7911, barren_land: 0.9603, building: 0.9761, grassland: 0.8891\n",
      "---------------\n",
      "fscore   , water: 0.9970, trees: 0.9661, road: 0.8681, barren_land: 0.9629, building: 0.9613, grassland: 0.9113\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "bookmark = {0: 'precision', 1: 'recall   ', 2: 'fscore   ', 3: 'support'}\n",
    "class_dict = {0: 'water', 1: 'trees', 2: 'road', 3: 'barren_land', 4: 'building', 5: 'grassland'}\n",
    "train_class_count = Counter(val_data.values())\n",
    "train_class_balance = {k:round(v/sum(train_class_count.values()),4) for k,v in train_class_count.items()}\n",
    "\n",
    "print('{}, {}: {:.4f}, {}: {:.4f}, {}: {:.4f}, {}: {:.4f}, {}: {:.4f}, {}: {:.4f}'\\\n",
    "              .format('balance  ',\n",
    "                      class_dict[0], train_class_balance[0],\n",
    "                      class_dict[1], train_class_balance[1],\n",
    "                      class_dict[2], train_class_balance[2],\n",
    "                      class_dict[3], train_class_balance[3],\n",
    "                      class_dict[4], train_class_balance[4],\n",
    "                      class_dict[5], train_class_balance[5]))\n",
    "\n",
    "print('---------------')\n",
    "\n",
    "for i, scores in enumerate(metrics.precision_recall_fscore_support(test_labels, preds)):\n",
    "    if i < 3:\n",
    "        print('{}, {}: {:.4f}, {}: {:.4f}, {}: {:.4f}, {}: {:.4f}, {}: {:.4f}, {}: {:.4f}'\\\n",
    "              .format(bookmark[i],\n",
    "                      class_dict[0], scores[0],\n",
    "                      class_dict[1], scores[1],\n",
    "                      class_dict[2], scores[2],\n",
    "                      class_dict[3], scores[3],\n",
    "                      class_dict[4], scores[4],\n",
    "                      class_dict[5], scores[5]))\n",
    "        print('---------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can tell, we have some evidence to suspect that the class inbalance is costing us performance. We note the following observations:\n",
    "\n",
    "    1. the class 'road' is grossly underrepresented in the training set, potentially leading to a low recall score and low overal performance (fscore: 0.8681)\n",
    "    \n",
    "    2. curiously, the class 'building', despite being underrepresented in the training set, obtained an acceptable prediction performance, possibly due to its visual distinctiveness\n",
    "    \n",
    "    3. on the contrary, the class 'grassland', despite having a relatively fair representation (15.43%), its recall score is below overal performance (fscore: 0.9113), leading us to believe that the class is harder to distinguish from other classes, especially from 'trees' and 'barren_land'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Going forward:\n",
    "\n",
    "The vanilla Random Forest's performance reached a respectable 96.5% accuracy with not excellent but acceptable class-wise performance, notably with minimum engineering. \n",
    "\n",
    "Going forward, we keep its performance as our baseline benchmark.\n",
    "\n",
    "We aim to improve the prediction performance of the model by artifitially balancing out the classes a bit by data augmentation of the 2 worst performing classes:\n",
    "\n",
    "    1. road: 2\n",
    "    2. grassland: 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Augmentation to deal with class inbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have written data augmentation functions (image_transformation.py) which provides the following image transformations:\n",
    "\n",
    "    1. random rotation between -25 and 25 degrees\n",
    "    2. random rotation between 26 and 75 degrees\n",
    "    3. random rotation either -90 or 90 degrees\n",
    "    4. adding random noise to the data\n",
    "    5. horizontal flip\n",
    "    6. vertical flip\n",
    "    7. transpose\n",
    "    8. zoom (maximum 1.4x)\n",
    "    \n",
    "With the 4 options, we can increase the representation of a particular class by 7 fold maximum without going into composite transformations\n",
    "    \n",
    "We will try 2 strategies:\n",
    "    1. Only augmenting the aforementioned 2 classes\n",
    "        a. to increase 8 fold the volume of the class 'road'\n",
    "        b. to increase 2 fold the volume of the class 'grassland'\n",
    "    2. Balancing all classes in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "from image_augmentation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dirs = [list(train_data.keys())[0], list(train_data.keys())[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 444.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the functions to be used for augmentation are: \n",
      "1 random_rotation_75\n",
      "2 random_rotation_90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_res = image_augmentation(test_dirs, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun_list = function_list = [random_rotation_25, random_rotation_75, random_rotation_90, random_noise, horizontal_flip, vertical_flip, transpose, zoom]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_rotation_25\n",
      "random_rotation_75\n",
      "random_rotation_90\n",
      "random_noise\n",
      "horizontal_flip\n",
      "vertical_flip\n",
      "transpose\n",
      "zoom\n"
     ]
    }
   ],
   "source": [
    "for fun in fun_list:\n",
    "    print(str(fun).split(' ')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice([90,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "li = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_arrays = [np.array([[1,2,3]]), np.array([[1,2,4]]), np.array([[1,5,4]])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "for arra in test_arrays:\n",
    "    li.append(arra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [1, 2, 4],\n",
       "       [1, 5, 4]])"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate(test_arrays, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [1, 2, 4],\n",
       "       [1, 2, 3],\n",
       "       [1, 2, 4],\n",
       "       [1, 5, 4]])"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate(li, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]] (1, 3)\n"
     ]
    }
   ],
   "source": [
    "print(li[0], li[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 3)"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate(li, axis = 0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.concatenate(li, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dmatrix = xgb.DMatrix(data = input_images, label = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_clf = xgb.XGBClassifier(objective='multi:softmax', colsample_bytree = 0.3, learning_rate = 0.1, max_depth = 100, alpha = 10, n_estimators=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_clf.fit(input_images,labels)\n",
    "\n",
    "preds = xg_reg.predict(test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
