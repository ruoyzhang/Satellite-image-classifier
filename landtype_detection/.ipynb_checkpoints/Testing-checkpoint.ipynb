{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import train\n",
    "from custom_dset_new import train_val_test_split, custom_dset\n",
    "from pretrained_inceptionv3 import pretrained_inception_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up variables\n",
    "data_dir = '../../data/images/'\n",
    "save_dir = '../../data/CNN_model_landtype/'\n",
    "num_class = 6\n",
    "bs = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/18900 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|â–ˆ         | 2022/18900 [07:17<1:00:52,  4.62it/s]Process Process-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/projects/aws_assignment/Assignment/landtype_detection/custom_dset_new.py\", line 135, in __getitem__\n",
      "    image = self.transform(image)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision-0.2.0-py3.6.egg/torchvision/transforms/transforms.py\", line 42, in __call__\n",
      "    img = t(img)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision-0.2.0-py3.6.egg/torchvision/transforms/transforms.py\", line 579, in __call__\n",
      "    return transform(img)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision-0.2.0-py3.6.egg/torchvision/transforms/transforms.py\", line 42, in __call__\n",
      "    img = t(img)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision-0.2.0-py3.6.egg/torchvision/transforms/transforms.py\", line 232, in __call__\n",
      "    return self.lambd(img)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision-0.2.0-py3.6.egg/torchvision/transforms/transforms.py\", line 562, in <lambda>\n",
      "    transforms.append(Lambda(lambda img: F.adjust_hue(img, hue_factor)))\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision-0.2.0-py3.6.egg/torchvision/transforms/functional.py\", line 491, in adjust_hue\n",
      "    img = Image.merge('HSV', (h, s, v)).convert(input_mode)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/Image.py\", line 933, in convert\n",
      "    im = self.im.convert(mode, dither)\n",
      "KeyboardInterrupt\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-3-4590281fa623>\", line 1, in <module>\n",
      "    loss_record, acc_record, model, test_data = train(data_dir = data_dir, save_dir = save_dir, num_class = 6, bs = bs, use_cuda = True)\n",
      "  File \"/home/paperspace/projects/aws_assignment/Assignment/landtype_detection/train.py\", line 116, in train\n",
      "    for inputs, labels in tqdm(dataloaders[phase]):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/tqdm/_tqdm.py\", line 953, in __iter__\n",
      "    for obj in iterable:\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 330, in __next__\n",
      "    idx, batch = self._get_batch()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 309, in _get_batch\n",
      "    return self.data_queue.get()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 1828, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1090, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/inspect.py\", line 1483, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/inspect.py\", line 1441, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/posixpath.py\", line 386, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/posixpath.py\", line 406, in _joinrealpath\n",
      "    name, _, rest = rest.partition(sep)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 227, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 4744) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "loss_record, acc_record, model, test_data = train(data_dir = data_dir, save_dir = save_dir, num_class = 6, bs = bs, use_cuda = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above error, the first dimension 4 comes from the batchsize = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_array = np.array([[1,2,3],[1,2,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tensor = torch.from_numpy(test_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models, transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(299),\n",
    "    transforms.CenterCrop(299),\n",
    "    transforms.ColorJitter(hue = .05, saturation = .05),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(90, resample = Image.BILINEAR),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_datasets = datasets.ImageFolder(data_dir, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = DataLoader(image_datasets, batch_size=4, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-7:\n",
      "Process Process-5:\n",
      "Process Process-6:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process Process-8:\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision-0.2.0-py3.6.egg/torchvision/datasets/folder.py\", line 124, in __getitem__\n",
      "    img = self.transform(img)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision-0.2.0-py3.6.egg/torchvision/transforms/transforms.py\", line 42, in __call__\n",
      "    img = t(img)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision-0.2.0-py3.6.egg/torchvision/datasets/folder.py\", line 124, in __getitem__\n",
      "    img = self.transform(img)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision-0.2.0-py3.6.egg/torchvision/transforms/transforms.py\", line 42, in __call__\n",
      "    img = t(img)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision-0.2.0-py3.6.egg/torchvision/transforms/transforms.py\", line 637, in __call__\n",
      "    return F.rotate(img, angle, self.resample, self.expand, self.center)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision-0.2.0-py3.6.egg/torchvision/datasets/folder.py\", line 124, in __getitem__\n",
      "    img = self.transform(img)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision-0.2.0-py3.6.egg/torchvision/transforms/functional.py\", line 552, in rotate\n",
      "    return img.rotate(angle, resample, expand, center)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision-0.2.0-py3.6.egg/torchvision/transforms/transforms.py\", line 42, in __call__\n",
      "    img = t(img)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/Image.py\", line 1651, in rotate\n",
      "    return self.transform((w, h), AFFINE, matrix, resample)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision-0.2.0-py3.6.egg/torchvision/transforms/transforms.py\", line 637, in __call__\n",
      "    return F.rotate(img, angle, self.resample, self.expand, self.center)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision-0.2.0-py3.6.egg/torchvision/transforms/functional.py\", line 552, in rotate\n",
      "    return img.rotate(angle, resample, expand, center)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/Image.py\", line 1902, in transform\n",
      "    im.__transformer((0, 0)+size, self, method, data, resample, fill)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/Image.py\", line 1953, in __transformer\n",
      "    self.im.transform2(box, image.im, method, data, resample, fill)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/Image.py\", line 1651, in rotate\n",
      "    return self.transform((w, h), AFFINE, matrix, resample)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision-0.2.0-py3.6.egg/torchvision/datasets/folder.py\", line 124, in __getitem__\n",
      "    img = self.transform(img)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/Image.py\", line 1902, in transform\n",
      "    im.__transformer((0, 0)+size, self, method, data, resample, fill)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision-0.2.0-py3.6.egg/torchvision/transforms/transforms.py\", line 42, in __call__\n",
      "    img = t(img)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision-0.2.0-py3.6.egg/torchvision/transforms/transforms.py\", line 637, in __call__\n",
      "    return F.rotate(img, angle, self.resample, self.expand, self.center)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/Image.py\", line 1953, in __transformer\n",
      "    self.im.transform2(box, image.im, method, data, resample, fill)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision-0.2.0-py3.6.egg/torchvision/transforms/functional.py\", line 552, in rotate\n",
      "    return img.rotate(angle, resample, expand, center)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/Image.py\", line 1651, in rotate\n",
      "    return self.transform((w, h), AFFINE, matrix, resample)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/Image.py\", line 1902, in transform\n",
      "    im.__transformer((0, 0)+size, self, method, data, resample, fill)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/Image.py\", line 1953, in __transformer\n",
      "    self.im.transform2(box, image.im, method, data, resample, fill)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-27-9f7dfc8aef5d>\", line 1, in <module>\n",
      "    for inputs, labels in dataloaders:\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 330, in __next__\n",
      "    idx, batch = self._get_batch()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 309, in _get_batch\n",
      "    return self.data_queue.get()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 1828, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/traitlets/traitlets.py\", line 528, in get\n",
      "    value = obj._trait_values[self.name]\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 227, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 8151) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2927, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 1831, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1371, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1279, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1128, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1073, in format_exception_as_a_whole\n",
      "    frames = self.format_records(records, last_unique, recursion_repeat)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 818, in format_records\n",
      "    frames.append(self.format_record(*r))\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 999, in format_record\n",
      "    _line_format = PyColorize.Parser(style=col_scheme, parent=self).format2\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/utils/PyColorize.py\", line 186, in __init__\n",
      "    super(Parser, self).__init__(parent=parent)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/traitlets/config/configurable.py\", line 67, in __init__\n",
      "    kwargs['config'] = parent.config\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/traitlets/traitlets.py\", line 556, in __get__\n",
      "    return self.get(obj, cls)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/traitlets/traitlets.py\", line 540, in get\n",
      "    raise TraitError('Unexpected error in TraitType: '\n",
      "traitlets.traitlets.TraitError: Unexpected error in TraitType: default value not set properly\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 1828, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TraitError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1090, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/inspect.py\", line 1483, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/inspect.py\", line 1445, in getframeinfo\n",
      "    lines, lnum = findsource(frame)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 177, in findsource\n",
      "    lines = linecache.getlines(file, globals_dict)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/linecache.py\", line 47, in getlines\n",
      "    return updatecache(filename, module_globals)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/linecache.py\", line 137, in updatecache\n",
      "    lines = fp.readlines()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/codecs.py\", line 318, in decode\n",
      "    def decode(self, input, final=False):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 227, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 7615) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.\n"
     ]
    }
   ],
   "source": [
    "for inputs, labels in dataloaders:\n",
    "    print(inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store', 'water', 'trees', 'road', 'barren_land', 'building', 'grassland']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a look at the custom dset and the train val test split class and func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir\n",
    "bs = 4\n",
    "num_workers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = custom_dset(data_dir = data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = DataLoader(dset, batch_size = bs, shuffle = True, num_workers = num_workers, pin_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n",
      "torch.Size([4, 3, 299, 299])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-3:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-9f7dfc8aef5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    307\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DataLoader timed out after {} seconds'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m         \u001b[0;31m# unserialize the data after having released the lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"negative maxlength\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bad_message_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxsize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"<ipython-input-22-4bddcda53fbf>\", line 78, in __getitem__\n",
      "    image = self.transform(image)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision-0.2.0-py3.6.egg/torchvision/transforms/transforms.py\", line 42, in __call__\n",
      "    img = t(img)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision-0.2.0-py3.6.egg/torchvision/transforms/transforms.py\", line 579, in __call__\n",
      "    return transform(img)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision-0.2.0-py3.6.egg/torchvision/transforms/transforms.py\", line 42, in __call__\n",
      "    img = t(img)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision-0.2.0-py3.6.egg/torchvision/transforms/transforms.py\", line 232, in __call__\n",
      "    return self.lambd(img)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision-0.2.0-py3.6.egg/torchvision/transforms/transforms.py\", line 562, in <lambda>\n",
      "    transforms.append(Lambda(lambda img: F.adjust_hue(img, hue_factor)))\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision-0.2.0-py3.6.egg/torchvision/transforms/functional.py\", line 491, in adjust_hue\n",
      "    img = Image.merge('HSV', (h, s, v)).convert(input_mode)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/Image.py\", line 933, in convert\n",
      "    im = self.im.convert(mode, dither)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "for inputs, labels in dataloaders:\n",
    "    print(inputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# we look at the model manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms, utils\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from torch.optim import Adam, SGD, lr_scheduler\n",
    "import math\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "from collections import Counter\n",
    "import time\n",
    "from pretrained_inceptionv3 import pretrained_inception_v3\n",
    "from custom_dset_new import custom_dset, train_val_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input variable values\n",
    "data_dir\n",
    "save_dir = '../../data/CNN_model_landtype/'\n",
    "num_class = 6\n",
    "use_cuda = True\n",
    "name = 'model'\n",
    "bs = 4\n",
    "lr = 1e-3\n",
    "num_workers = 1\n",
    "train_prop = 0.7\n",
    "val_prop = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pretrained_inception_v3(num_class, use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(save_dir):\n",
    "    os.mkdir(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath = os.path.join(save_dir, '{}.pt'.format(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in the case of paused training, do we wish to continue training?\n",
    "if use_cuda:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fun = torch.nn.CrossEntropyLoss(reduction = 'sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = SGD(model.parameters(), lr = lr, momentum = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_lr_scheduler = lr_scheduler.StepLR(optim, step_size = 7, gamma = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = custom_dset(data_dir = data_dir, transform = 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prop = 1 - train_prop - val_prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data, test_data = train_val_test_split(data_dir, train_prop, val_prop, test_prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(226800, 64800, 32400)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(val_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_class_sample_count = Counter(dset.dir_to_class_dict[dset.all_files[i]] for i in train_data.indices)\n",
    "sorted_train_class_sample_count = [train_class_sample_count[key] for key in sorted(train_class_sample_count.keys())]\n",
    "weights = 100000./torch.tensor(sorted_train_class_sample_count, dtype = torch.float)\n",
    "samples_weights = [weights[label] for label in train_data.dataset.labels]\n",
    "# the sampler\n",
    "sampler = WeightedRandomSampler(weights=samples_weights,\n",
    "                                num_samples=len(samples_weights),\n",
    "                                replacement=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {'train': DataLoader(train_data, batch_size = bs, sampler = sampler, num_workers = num_workers, pin_memory = False),\n",
    "               'val': DataLoader(val_data, batch_size = bs, shuffle = True, num_workers = num_workers, pin_memory = False)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase = 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_lr_scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pretrained_inception_v3(\n",
       "  (model): Inception3(\n",
       "    (Conv2d_1a_3x3): BasicConv2d(\n",
       "      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (Conv2d_2a_3x3): BasicConv2d(\n",
       "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (Conv2d_2b_3x3): BasicConv2d(\n",
       "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (Conv2d_3b_1x1): BasicConv2d(\n",
       "      (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (Conv2d_4a_3x3): BasicConv2d(\n",
       "      (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (Mixed_5b): InceptionA(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_2): BasicConv2d(\n",
       "        (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_5c): InceptionA(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_2): BasicConv2d(\n",
       "        (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_5d): InceptionA(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_2): BasicConv2d(\n",
       "        (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6a): InceptionB(\n",
       "      (branch3x3): BasicConv2d(\n",
       "        (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6b): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6c): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6d): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6e): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (AuxLogits): InceptionAux(\n",
       "      (conv0): BasicConv2d(\n",
       "        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv1): BasicConv2d(\n",
       "        (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (fc): Linear(in_features=768, out_features=1000, bias=True)\n",
       "    )\n",
       "    (Mixed_7a): InceptionD(\n",
       "      (branch3x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_3): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_4): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_7b): InceptionE(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_7c): InceptionE(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (fc): Linear(in_features=2048, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/81000 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "for inputs, labels in tqdm(dataloaders[phase]):\n",
    "    # counting how many images is contained in this batch\n",
    "    batch_count = labels.size(0)\n",
    "    # if GPU is used, cudafy inputs\n",
    "    if use_cuda:\n",
    "        inputs = inputs.cuda()\n",
    "        labels = labels.cuda()\n",
    "    # zero the parameter gradients\n",
    "    optim.zero_grad()\n",
    "    # feed inputs into the model\n",
    "    output = model(inputs)\n",
    "    hi = 1\n",
    "    if hi == 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.1202, -0.1006, -0.6060,  0.3510,  0.3571, -0.0173],\n",
       "         [ 0.1690, -0.3432, -0.3223,  0.4137,  0.2538,  0.3367],\n",
       "         [-0.0371, -0.1204, -0.1848, -0.0395, -0.2590,  0.2885],\n",
       "         [-0.3932, -0.5033, -0.0287,  0.0057, -0.1109,  0.1864]],\n",
       "        device='cuda:0', grad_fn=<ThAddmmBackward>),\n",
       " tensor([[ 3.3164,  2.8084,  3.9702,  ..., -0.9659,  1.2601, -0.4750],\n",
       "         [-2.0469, -3.2330, -0.7512,  ...,  0.7375, -0.4753, -0.0281],\n",
       "         [-2.2449, -1.5670, -1.8169,  ..., -0.0006,  1.5303,  1.7633],\n",
       "         [ 0.1517,  1.3607, -2.0299,  ..., -0.5026, -1.6757, -0.4374]],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/81000 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "for inputs, labels in tqdm(dataloaders[phase]):\n",
    "    # counting how many images is contained in this batch\n",
    "    batch_count = labels.size(0)\n",
    "    # if GPU is used, cudafy inputs\n",
    "    if use_cuda:\n",
    "        inputs = inputs.cuda()\n",
    "        labels = labels.cuda()\n",
    "    # zero the parameter gradients\n",
    "    optim.zero_grad()\n",
    "    # feed inputs into the model\n",
    "    output = model(inputs)\n",
    "    if type(output) == tuple:\n",
    "        output, _ = output\n",
    "    _, preds = torch.max(output.data, 1)\n",
    "    \n",
    "    hi = 1\n",
    "    if hi == 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 4, 2, 5], device='cuda:0')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oops\n"
     ]
    }
   ],
   "source": [
    "hi = 4\n",
    "if hi == 5:\n",
    "    print('hi')\n",
    "else:\n",
    "    print('oops')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
