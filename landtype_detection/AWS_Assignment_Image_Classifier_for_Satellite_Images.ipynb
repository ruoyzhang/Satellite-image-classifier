{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classifier for Satellite Images Using Non Deep Learning and Deep Learning Methods\n",
    "\n",
    "This notebook demonstrates how we construct an image classifier using non deep learning methods.\n",
    "\n",
    "More specifically, it will cover the following topics in order:\n",
    "\n",
    "## Agenda \n",
    "####    1. Data Preparation: converting image data into vector form\n",
    "####    2. Vanilla Random Forest as a benchmark\n",
    "####    3. Data Augmentation to deal with class inbalance\n",
    "####    4. Random Forest with augmented data\n",
    "            4.1 Strategy 1\n",
    "            4.2 Strategy 2\n",
    "            4.3 Strategy 3\n",
    "####    5. Performance comparison with CNN using pretrained InceptionV3\n",
    "            5.1 The CNN architecture\n",
    "            5.2 Performance comparison\n",
    "####    6. Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preparation: converting image data into vector form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. We conver the image files into single dimension vectors of 28 * 28 * 3 dimensions\n",
    "2. We will also convert the image classes into integers using the following scheme:\n",
    "\n",
    "    {'water':0, 'trees':1, 'road':2, 'barren_land': 3, 'building': 4, 'grassland':5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from custom_dset_new import train_val_test_split\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the directory to the image data\n",
    "data_dir = '/Users/ruoyangzhang/Documents/PythonWorkingDirectory/Assignment_data/images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into train and test\n",
    "# we use the function that we created for the Convolution Neural Net\n",
    "# Since there is barely any hyper parameters for with the Random Forest Algorithm, we set val_proportion = 0\n",
    "train_data, val_data, test_data = train_val_test_split(data_dir, train_split=0.8, val_split=0.0, test_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional step to remove unwanted sys files \n",
    "ordered_train_dirs = [dir for dir in sorted(list(train_data.keys())) if os.path.split(dir)[-1] != '.DS_Store']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert the images to a vector\n",
    "def convert_to_vector(img_dir):\n",
    "    img = cv2.imread(img_dir)\n",
    "    b, g, r = cv2.split(img)\n",
    "    rgb_img = cv2.merge([r, g, b])\n",
    "    rgb_img.shape = (1, 28*28*3)\n",
    "    return(rgb_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 259200/259200 [02:10<00:00, 1982.67it/s]\n"
     ]
    }
   ],
   "source": [
    "# convert training images to input data\n",
    "input_images = np.array([convert_to_vector(dir) for dir in tqdm(ordered_train_dirs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape training input data\n",
    "input_images.shape = (input_images.shape[0], input_images.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct training input labels\n",
    "train_labels = np.array([train_data[dir] for dir in ordered_train_dirs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we make test data into np.arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional step to remove unwanted sys files \n",
    "ordered_test_dirs = [testdir for testdir in sorted(list(test_data.keys())) if os.path.split(testdir)[-1] != '.DS_Store']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64800/64800 [00:36<00:00, 1792.34it/s]\n"
     ]
    }
   ],
   "source": [
    "# convert testing images to input data\n",
    "test_images = np.array([convert_to_vector(dir) for dir in tqdm(ordered_test_dirs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape test input data\n",
    "test_images.shape = (test_images.shape[0], test_images.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct test input labels\n",
    "test_labels = np.array([test_data[testdir] for testdir in ordered_test_dirs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Vanilla Random Forest as a benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We opt to use the Random Forest algorithm for the particular mission for the following reasons:\n",
    "\n",
    "    1. Its robust performance\n",
    "    \n",
    "    2. Its lack of hyper parameter tuning, this is vital since the image dataset is large (> 300k images), the training time can be significant and hyperparameter tuning should be minimised given the time constraints\n",
    "    \n",
    "    3. It's quick to train\n",
    "    \n",
    "    4. Excellent free open source implementation (Sklearn)\n",
    "    \n",
    "    5. Simplicity\n",
    "    \n",
    "We note also the disadvantage of the Random Forest algorithm:\n",
    "\n",
    "    1. Its model size can easily get quite large and evaluation can be relatively slow\n",
    "    \n",
    "    2. The lack of interpretability. While decision trees are easy to interpret, a forest is not so much. Random Forest is regarded by some as a blackbox due to the weighting mechanism behind its decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn import metrics\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, n_jobs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=5,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model to the data\n",
    "clf.fit(input_images,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "preds = clf.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.966358024691358\n"
     ]
    }
   ],
   "source": [
    "# evaluate the accuracy\n",
    "print(\"Accuracy:\",metrics.accuracy_score(test_labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[24137,     0,     0,     0,     0,     0],\n",
       "       [   10, 11285,     0,     5,     0,    62],\n",
       "       [   83,    30,  1282,    26,   134,    44],\n",
       "       [    1,    44,     0, 14050,    31,   480],\n",
       "       [   18,     0,    39,     2,  2943,     0],\n",
       "       [   35,   650,     3,   483,     0,  8923]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the confusion matrix\n",
    "metrics.confusion_matrix(test_labels, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balance  , water: 0.3725, trees: 0.1753, road: 0.0247, barren_land: 0.2254, building: 0.0463, grassland: 0.1558\n",
      "---------------\n",
      "precision, water: 0.9939, trees: 0.9397, road: 0.9683, barren_land: 0.9646, building: 0.9469, grassland: 0.9384\n",
      "---------------\n",
      "recall   , water: 1.0000, trees: 0.9932, road: 0.8018, barren_land: 0.9619, building: 0.9803, grassland: 0.8840\n",
      "---------------\n",
      "fscore   , water: 0.9970, trees: 0.9657, road: 0.8772, barren_land: 0.9633, building: 0.9633, grassland: 0.9104\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "# its precision, recall and fscore in relation to the proportion of each class in the training data\n",
    "\n",
    "bookmark = {0: 'precision', 1: 'recall   ', 2: 'fscore   ', 3: 'support'}\n",
    "class_dict = {0: 'water', 1: 'trees', 2: 'road', 3: 'barren_land', 4: 'building', 5: 'grassland'}\n",
    "train_class_count = Counter(test_data.values())\n",
    "train_class_balance = {k:round(v/sum(train_class_count.values()),4) for k,v in train_class_count.items()}\n",
    "\n",
    "print('{}, {}: {:.4f}, {}: {:.4f}, {}: {:.4f}, {}: {:.4f}, {}: {:.4f}, {}: {:.4f}'\\\n",
    "              .format('balance  ',\n",
    "                      class_dict[0], train_class_balance[0],\n",
    "                      class_dict[1], train_class_balance[1],\n",
    "                      class_dict[2], train_class_balance[2],\n",
    "                      class_dict[3], train_class_balance[3],\n",
    "                      class_dict[4], train_class_balance[4],\n",
    "                      class_dict[5], train_class_balance[5]))\n",
    "\n",
    "print('---------------')\n",
    "\n",
    "for i, scores in enumerate(metrics.precision_recall_fscore_support(test_labels, preds)):\n",
    "    if i < 3:\n",
    "        print('{}, {}: {:.4f}, {}: {:.4f}, {}: {:.4f}, {}: {:.4f}, {}: {:.4f}, {}: {:.4f}'\\\n",
    "              .format(bookmark[i],\n",
    "                      class_dict[0], scores[0],\n",
    "                      class_dict[1], scores[1],\n",
    "                      class_dict[2], scores[2],\n",
    "                      class_dict[3], scores[3],\n",
    "                      class_dict[4], scores[4],\n",
    "                      class_dict[5], scores[5]))\n",
    "        print('---------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can tell, we have some evidence to suspect that the class inbalance is costing us performance. We note the following observations:\n",
    "\n",
    "    1. the class 'road' is grossly underrepresented in the training set, potentially leading to a low recall score and low overal performance (fscore: 0.8772)\n",
    "    \n",
    "    2. curiously, the class 'building', despite being underrepresented in the training set, obtained an acceptable prediction performance, possibly due to its visual distinctiveness\n",
    "    \n",
    "    3. on the contrary, the class 'grassland', despite having a relatively fair representation (15.58%), its recall score is below overal performance (fscore: 0.9104), leading us to believe that the class is harder to distinguish from other classes, especially from 'trees' and 'barren_land'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Going forward:\n",
    "\n",
    "The vanilla Random Forest's performance reached a respectable 96.5% accuracy with not excellent but acceptable class-wise performance, notably with minimum engineering. \n",
    "\n",
    "Going forward, we keep its performance as our baseline benchmark.\n",
    "\n",
    "We aim to improve the prediction performance of the model by artifitially balancing out the classes a bit by data augmentation of the 2 worst performing classes:\n",
    "\n",
    "    1. road: 2\n",
    "    2. grassland: 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Augmentation to deal with class inbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have written data augmentation functions (image_augmentation.py) which provides the following image transformations:\n",
    "\n",
    "    1. random rotation between -25 and 25 degrees\n",
    "    2. random rotation between 26 and 75 degrees\n",
    "    3. random rotation either -90 or 90 degrees\n",
    "    4. adding random noise to the data\n",
    "    5. horizontal flip\n",
    "    6. vertical flip\n",
    "    7. transpose\n",
    "    8. zoom (maximum 1.4x)\n",
    "    \n",
    "With the 8 options, we can increase the representation of a particular class by 8 fold maximum without going into composite transformations\n",
    "    \n",
    "We will try 3 strategies in order to evaluate which data augmentation gives us the most desired result:\n",
    "\n",
    "    1. strategy 1\n",
    "        a. to increase 2 fold the volume of the class 'road'\n",
    "        b. to increase 2 fold the volume of the class 'grassland'\n",
    "    2. Strategy 2\n",
    "        a. to increase 4 fold the volume of the class 'road'\n",
    "        b. to increase 2 fold the volume of the class 'grassland'\n",
    "    3. Strategy 3\n",
    "        a. to increase 3 fold the volume of the class 'road'\n",
    "        b. to increase 2 fold the volume of the class 'grassland'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from image_augmentation import *\n",
    "\n",
    "# set fold variables for the 2 classes\n",
    "class_2_fold = 2\n",
    "class_5_fold = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first prep the augmented training data and the respective labels for class 2 and 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we first extract the image_dirs for class 2 & 5\n",
    "class_2_dirs = [ordered_train_dirs[i] for i, cls in enumerate(train_labels) if cls == 2]\n",
    "class_2_labels = np.array([2] * len(class_2_dirs) * class_2_fold)\n",
    "class_5_dirs = [ordered_train_dirs[i] for i, cls in enumerate(train_labels) if cls == 5]\n",
    "class_5_labels = np.array([5] * len(class_5_dirs) * class_5_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 146/6593 [00:00<00:08, 723.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the functions to be used for augmentation are: \n",
      "1 random_rotation_75\n",
      "2 random_rotation_90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6593/6593 [00:08<00:00, 807.71it/s]\n"
     ]
    }
   ],
   "source": [
    "# we then augment the data for class 2\n",
    "augmented_class_2 = image_augmentation(class_2_dirs, class_2_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 195/40253 [00:00<00:41, 970.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the functions to be used for augmentation are: \n",
      "1 random_rotation_75\n",
      "2 horizontal_flip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40253/40253 [00:39<00:00, 1024.45it/s]\n"
     ]
    }
   ],
   "source": [
    "# we then augment the data for class 5\n",
    "augmented_class_5 = image_augmentation(class_5_dirs, class_5_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new input data and labels\n",
    "input_images_aug = np.concatenate((input_images,augmented_class_2,augmented_class_5), axis = 0)\n",
    "train_labels_aug = np.concatenate((train_labels, class_2_labels, class_5_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set fold variables for the 2 classes\n",
    "class_2_fold_2 = 4\n",
    "class_5_fold_2 = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we make the labels for the augmented data for class 2\n",
    "class_2_labels_2 = np.array([2] * len(class_2_dirs) * class_2_fold_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6593 [00:00<?, ?it/s]/Users/ruoyangzhang/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "  2%|▏         | 145/6593 [00:00<00:08, 721.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the functions to be used for augmentation are: \n",
      "1 vertical_flip\n",
      "2 horizontal_flip\n",
      "3 random_rotation_90\n",
      "4 zoom\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6593/6593 [00:09<00:00, 694.62it/s]\n"
     ]
    }
   ],
   "source": [
    "# we then augment the data for class 2\n",
    "augmented_class_2_2 = image_augmentation(class_2_dirs, class_2_fold_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new input data and labels\n",
    "input_images_aug_2 = np.concatenate((input_images,augmented_class_2_2,augmented_class_5), axis = 0)\n",
    "train_labels_aug_2 = np.concatenate((train_labels, class_2_labels_2, class_5_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set fold variables for the 2 classes\n",
    "class_2_fold_3 = 3\n",
    "class_5_fold_3 = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we make the labels for the augmented data for class 2\n",
    "class_2_labels_3 = np.array([2] * len(class_2_dirs) * class_2_fold_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 40/6593 [00:00<00:16, 399.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the functions to be used for augmentation are: \n",
      "1 random_rotation_90\n",
      "2 random_rotation_75\n",
      "3 horizontal_flip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6593/6593 [00:08<00:00, 800.33it/s]\n"
     ]
    }
   ],
   "source": [
    "# we then augment the data for class 2\n",
    "augmented_class_2_3 = image_augmentation(class_2_dirs, class_2_fold_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new input data and labels\n",
    "input_images_aug_3 = np.concatenate((input_images,augmented_class_2_3,augmented_class_5), axis = 0)\n",
    "train_labels_aug_3 = np.concatenate((train_labels, class_2_labels_3, class_5_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  4. Random Forest with augmented data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Strategy 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the classifier\n",
    "clf_aug = RandomForestClassifier(n_estimators=100, n_jobs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=5,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model to the data\n",
    "clf_aug.fit(input_images_aug,train_labels_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "preds_new = clf_aug.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9700308641975308\n"
     ]
    }
   ],
   "source": [
    "# evaluate the accuracy\n",
    "print(\"Accuracy:\",metrics.accuracy_score(test_labels, preds_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[24137,     0,     0,     0,     0,     0],\n",
       "       [   10, 11285,     0,     5,     0,    62],\n",
       "       [   83,    30,  1282,    26,   134,    44],\n",
       "       [    1,    44,     0, 14050,    31,   480],\n",
       "       [   18,     0,    39,     2,  2943,     0],\n",
       "       [   35,   650,     3,   483,     0,  8923]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the confusion matrix\n",
    "metrics.confusion_matrix(test_labels, preds_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balance  , water: 0.2726, trees: 0.1288, road: 0.0560, barren_land: 0.1666, building: 0.0338, grassland: 0.3422\n",
      "---------------\n",
      "precision, water: 0.9946, trees: 0.9669, road: 0.9709, barren_land: 0.9823, building: 0.9463, grassland: 0.9072\n",
      "---------------\n",
      "recall   , water: 1.0000, trees: 0.9843, road: 0.7724, barren_land: 0.9460, building: 0.9800, grassland: 0.9453\n",
      "---------------\n",
      "fscore   , water: 0.9973, trees: 0.9755, road: 0.8603, barren_land: 0.9638, building: 0.9629, grassland: 0.9259\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "# its precision, recall and fscore in relation to the proportion of each class in the training data\n",
    "\n",
    "bookmark = {0: 'precision', 1: 'recall   ', 2: 'fscore   ', 3: 'support'}\n",
    "class_dict = {0: 'water', 1: 'trees', 2: 'road', 3: 'barren_land', 4: 'building', 5: 'grassland'}\n",
    "train_class_count_aug = Counter(train_labels_aug)\n",
    "train_class_balance_aug = {k:round(v/sum(train_class_count_aug.values()),4) for k,v in train_class_count_aug.items()}\n",
    "\n",
    "print('{}, {}: {:.4f}, {}: {:.4f}, {}: {:.4f}, {}: {:.4f}, {}: {:.4f}, {}: {:.4f}'\\\n",
    "              .format('balance  ',\n",
    "                      class_dict[0], train_class_balance_aug[0],\n",
    "                      class_dict[1], train_class_balance_aug[1],\n",
    "                      class_dict[2], train_class_balance_aug[2],\n",
    "                      class_dict[3], train_class_balance_aug[3],\n",
    "                      class_dict[4], train_class_balance_aug[4],\n",
    "                      class_dict[5], train_class_balance_aug[5]))\n",
    "\n",
    "print('---------------')\n",
    "\n",
    "for i, scores in enumerate(metrics.precision_recall_fscore_support(test_labels, preds_new)):\n",
    "    if i < 3:\n",
    "        print('{}, {}: {:.4f}, {}: {:.4f}, {}: {:.4f}, {}: {:.4f}, {}: {:.4f}, {}: {:.4f}'\\\n",
    "              .format(bookmark[i],\n",
    "                      class_dict[0], scores[0],\n",
    "                      class_dict[1], scores[1],\n",
    "                      class_dict[2], scores[2],\n",
    "                      class_dict[3], scores[3],\n",
    "                      class_dict[4], scores[4],\n",
    "                      class_dict[5], scores[5]))\n",
    "        print('---------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Strategy 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the classifier\n",
    "clf_aug_2 = RandomForestClassifier(n_estimators=100, n_jobs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=5,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model to the data\n",
    "clf_aug_2.fit(input_images_aug_2,train_labels_aug_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "preds_new_2 = clf_aug_2.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9695370370370371\n"
     ]
    }
   ],
   "source": [
    "# evaluate the accuracy\n",
    "print(\"Accuracy:\",metrics.accuracy_score(test_labels, preds_new_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[24136,     0,     1,     0,     0,     0],\n",
       "       [   14, 11182,     1,     2,     0,   163],\n",
       "       [   42,    28,  1455,     8,    35,    31],\n",
       "       [    1,    40,    13, 13828,    23,   701],\n",
       "       [    5,     1,   291,     1,  2702,     2],\n",
       "       [   18,   326,     6,   221,     0,  9523]])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the confusion matrix\n",
    "metrics.confusion_matrix(test_labels, preds_new_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balance  , water: 0.2628, trees: 0.1241, road: 0.0900, barren_land: 0.1606, building: 0.0326, grassland: 0.3299\n",
      "---------------\n",
      "precision, water: 0.9967, trees: 0.9659, road: 0.8234, barren_land: 0.9835, building: 0.9790, grassland: 0.9139\n",
      "---------------\n",
      "recall   , water: 1.0000, trees: 0.9842, road: 0.9099, barren_land: 0.9467, building: 0.9001, grassland: 0.9434\n",
      "---------------\n",
      "fscore   , water: 0.9983, trees: 0.9749, road: 0.8645, barren_land: 0.9648, building: 0.9379, grassland: 0.9284\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "# its precision, recall and fscore in relation to the proportion of each class in the training data\n",
    "\n",
    "bookmark = {0: 'precision', 1: 'recall   ', 2: 'fscore   ', 3: 'support'}\n",
    "class_dict = {0: 'water', 1: 'trees', 2: 'road', 3: 'barren_land', 4: 'building', 5: 'grassland'}\n",
    "train_class_count_aug_2 = Counter(train_labels_aug_2)\n",
    "train_class_balance_aug_2 = {k:round(v/sum(train_class_count_aug_2.values()),4) for k,v in train_class_count_aug_2.items()}\n",
    "\n",
    "print('{}, {}: {:.4f}, {}: {:.4f}, {}: {:.4f}, {}: {:.4f}, {}: {:.4f}, {}: {:.4f}'\\\n",
    "              .format('balance  ',\n",
    "                      class_dict[0], train_class_balance_aug_2[0],\n",
    "                      class_dict[1], train_class_balance_aug_2[1],\n",
    "                      class_dict[2], train_class_balance_aug_2[2],\n",
    "                      class_dict[3], train_class_balance_aug_2[3],\n",
    "                      class_dict[4], train_class_balance_aug_2[4],\n",
    "                      class_dict[5], train_class_balance_aug_2[5]))\n",
    "\n",
    "print('---------------')\n",
    "\n",
    "for i, scores in enumerate(metrics.precision_recall_fscore_support(test_labels, preds_new_2)):\n",
    "    if i < 3:\n",
    "        print('{}, {}: {:.4f}, {}: {:.4f}, {}: {:.4f}, {}: {:.4f}, {}: {:.4f}, {}: {:.4f}'\\\n",
    "              .format(bookmark[i],\n",
    "                      class_dict[0], scores[0],\n",
    "                      class_dict[1], scores[1],\n",
    "                      class_dict[2], scores[2],\n",
    "                      class_dict[3], scores[3],\n",
    "                      class_dict[4], scores[4],\n",
    "                      class_dict[5], scores[5]))\n",
    "        print('---------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Strategy 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the classifier\n",
    "clf_aug_3 = RandomForestClassifier(n_estimators=100, n_jobs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=5,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model to the data\n",
    "clf_aug_3.fit(input_images_aug_3,train_labels_aug_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "preds_new_3 = clf_aug_3.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9702006172839506\n"
     ]
    }
   ],
   "source": [
    "# evaluate the accuracy\n",
    "print(\"Accuracy:\",metrics.accuracy_score(test_labels, preds_new_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[24137,     0,     0,     0,     0,     0],\n",
       "       [   16, 11183,     0,     1,     0,   162],\n",
       "       [   50,    30,  1395,    10,    57,    57],\n",
       "       [    1,    42,    10, 13817,    23,   713],\n",
       "       [   15,     0,   170,     1,  2814,     2],\n",
       "       [   17,   327,     4,   223,     0,  9523]])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the confusion matrix\n",
    "metrics.confusion_matrix(test_labels, preds_new_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balance  , water: 0.2676, trees: 0.1264, road: 0.0734, barren_land: 0.1635, building: 0.0332, grassland: 0.3359\n",
      "---------------\n",
      "precision, water: 0.9959, trees: 0.9655, road: 0.8835, barren_land: 0.9833, building: 0.9724, grassland: 0.9107\n",
      "---------------\n",
      "recall   , water: 1.0000, trees: 0.9842, road: 0.8724, barren_land: 0.9460, building: 0.9374, grassland: 0.9434\n",
      "---------------\n",
      "fscore   , water: 0.9980, trees: 0.9748, road: 0.8779, barren_land: 0.9643, building: 0.9545, grassland: 0.9268\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "# its precision, recall and fscore in relation to the proportion of each class in the training data\n",
    "\n",
    "bookmark = {0: 'precision', 1: 'recall   ', 2: 'fscore   ', 3: 'support'}\n",
    "class_dict = {0: 'water', 1: 'trees', 2: 'road', 3: 'barren_land', 4: 'building', 5: 'grassland'}\n",
    "train_class_count_aug_3 = Counter(train_labels_aug_3)\n",
    "train_class_balance_aug_3 = {k:round(v/sum(train_class_count_aug_3.values()),4) for k,v in train_class_count_aug_3.items()}\n",
    "\n",
    "print('{}, {}: {:.4f}, {}: {:.4f}, {}: {:.4f}, {}: {:.4f}, {}: {:.4f}, {}: {:.4f}'\\\n",
    "              .format('balance  ',\n",
    "                      class_dict[0], train_class_balance_aug_3[0],\n",
    "                      class_dict[1], train_class_balance_aug_3[1],\n",
    "                      class_dict[2], train_class_balance_aug_3[2],\n",
    "                      class_dict[3], train_class_balance_aug_3[3],\n",
    "                      class_dict[4], train_class_balance_aug_3[4],\n",
    "                      class_dict[5], train_class_balance_aug_3[5]))\n",
    "\n",
    "print('---------------')\n",
    "\n",
    "for i, scores in enumerate(metrics.precision_recall_fscore_support(test_labels, preds_new_3)):\n",
    "    if i < 3:\n",
    "        print('{}, {}: {:.4f}, {}: {:.4f}, {}: {:.4f}, {}: {:.4f}, {}: {:.4f}, {}: {:.4f}'\\\n",
    "              .format(bookmark[i],\n",
    "                      class_dict[0], scores[0],\n",
    "                      class_dict[1], scores[1],\n",
    "                      class_dict[2], scores[2],\n",
    "                      class_dict[3], scores[3],\n",
    "                      class_dict[4], scores[4],\n",
    "                      class_dict[5], scores[5]))\n",
    "        print('---------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Performance comparison with CNN using pretrained InceptionV3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 The CNN Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We applied the transfer learning technique to avoid retrainning the model from scratch.\n",
    "We used the pretrained InceptionV3 model provided by the PyTorch framework for the following reasons:\n",
    "    1. Its relative light weight for training in comparison with other popular architectures such as Resnet or VGG\n",
    "    2. Its availability in torch.vision (there are other light architectures such as mobilenet but they are not readily available in torch.vision)\n",
    "    3. Its rebust performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We trained multiple models using this architecture:\n",
    "\n",
    "Shared variables:\n",
    "\n",
    "Optimisation: SGD\n",
    "\n",
    "Loss Function: Cross Entropy\n",
    "\n",
    "Batchsize: 32\n",
    "\n",
    "Group 1, 8 training epochs:\n",
    "    1. fully connected layers unfrozen, decaying learning rate 1e-3, step size = 7, gamma = 0.1\n",
    "    2. layers after 'Conv2d_4a_3x3' unfrozen, decaying learning rate 1e-3, step size = 7, gamma = 0.1\n",
    "Group 2, 4 training epochs:\n",
    "    1. fully connected layers unfrozen & decaying learning rate 1e-5, step size = 3, gamma = 0.2\n",
    "    2. layers after 'Conv2d_4a_3x3' unfrozen, decaying learning rate 1e-5, step size = 3, gamma = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group 2 performed better on the validation set with considerably less training data:\n",
    "\n",
    "Best alidation accuracy:\n",
    "\n",
    "    Group 1:\n",
    "        1. 0.8789\n",
    "        2. 0.8827\n",
    "    Group 2:\n",
    "        1. 0.9043\n",
    "        2. 0.9207    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We finally kept the 2nd model from group 2.\n",
    "\n",
    "We chose not to further tune the hyper parameter or run any more epochs since the Random Forest algorithm provides a much superior performance in terms of accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
