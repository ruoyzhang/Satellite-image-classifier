
% Default to the notebook output style

    


% Inherit from the specified cell style.




    
\documentclass[11pt]{article}

    
    
    \usepackage[T1]{fontenc}
    % Nicer default font (+ math font) than Computer Modern for most use cases
    \usepackage{mathpazo}

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % We will generate all images so they have a width \maxwidth. This means
    % that they will get their normal width if they fit onto the page, but
    % are scaled down if they would overflow the margins.
    \makeatletter
    \def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth
    \else\Gin@nat@width\fi}
    \makeatother
    \let\Oldincludegraphics\includegraphics
    % Set max figure width to be 80% of text width, for now hardcoded.
    \renewcommand{\includegraphics}[1]{\Oldincludegraphics[width=.8\maxwidth]{#1}}
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionLabelFormat{nolabel}{}
    \captionsetup{labelformat=nolabel}

    \usepackage{adjustbox} % Used to constrain images to a maximum size 
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage[utf8x]{inputenc} % Allow utf-8 characters in the tex document
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range 
    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    

    
    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}
    
    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    
    
    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatability definitions
    \def\gt{>}
    \def\lt{<}
    % Document parameters
    \title{AWS\_Assignment\_Image\_Classifier\_for\_Satellite\_Images}
    
    
    

    % Pygments definitions
    
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\expandafter\def\csname PY@tok@w\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PY@tok@c\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\expandafter\def\csname PY@tok@k\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\expandafter\def\csname PY@tok@o\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ow\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@nb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@ne\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\expandafter\def\csname PY@tok@nv\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@no\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@nl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@ni\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\expandafter\def\csname PY@tok@na\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\expandafter\def\csname PY@tok@nt\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@s\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sd\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@si\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@se\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\expandafter\def\csname PY@tok@sr\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@ss\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sx\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@m\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@gh\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gu\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@gi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@gr\endcsname{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@ge\endcsname{\let\PY@it=\textit}
\expandafter\def\csname PY@tok@gs\endcsname{\let\PY@bf=\textbf}
\expandafter\def\csname PY@tok@gp\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@go\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PY@tok@gt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PY@tok@err\endcsname{\def\PY@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PY@tok@kc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kd\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kr\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@bp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@fm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@vc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vg\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sa\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@dl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s2\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s1\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@mb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@il\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mo\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ch\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cm\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cpf\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@c1\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cs\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % Exact colors from NB
    \definecolor{incolor}{rgb}{0.0, 0.0, 0.5}
    \definecolor{outcolor}{rgb}{0.545, 0.0, 0.0}



    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy 
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

    \begin{document}
    
    
    \maketitle
    
    

    
    \section{Image Classifier for Satellite Images Using Non Deep Learning
and Deep Learning
Methods}\label{image-classifier-for-satellite-images-using-non-deep-learning-and-deep-learning-methods}

\textbf{Author}: Ruoyang ZHANG

This notebook demonstrates how we construct an image classifier using
non deep learning methods.

More specifically, it will cover the following topics in order:

\subsection{Agenda}\label{agenda}

\paragraph{1. Data Preparation: converting image data into vector
form}\label{data-preparation-converting-image-data-into-vector-form}

\paragraph{2. Vanilla Random Forest as a
benchmark}\label{vanilla-random-forest-as-a-benchmark}

\paragraph{3. Data Augmentation to deal with class
inbalance}\label{data-augmentation-to-deal-with-class-inbalance}

\paragraph{4. Random Forest with augmented
data}\label{random-forest-with-augmented-data}

\begin{verbatim}
        4.1 Strategy 1
        4.2 Strategy 2
        4.3 Strategy 3
        4.4 Discussion
\end{verbatim}

\paragraph{5. Performance comparison with CNN using pretrained
InceptionV3}\label{performance-comparison-with-cnn-using-pretrained-inceptionv3}

\paragraph{6. Conclusions}\label{conclusions}

\paragraph{7. Appendix - all functions and classes contained in seperate
.py
files}\label{appendix---all-functions-and-classes-contained-in-seperate-.py-files}

\begin{verbatim}
        7.1 image_augmentation.py (Random Forest)
        7.2 custom_dset_new_alt.py (Random Forest & CNN)
        7.3 pretrained_inceptionv3_alt.py (CNN)
        7.4 train_alt.py (CNN)
        7.5 test_alt.py (CNN)
        7.6 execute_training_alt.py (CNN)
\end{verbatim}

    \begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

    \subsection{1. Data Preparation: converting image data into vector
form}\label{data-preparation-converting-image-data-into-vector-form}

    \begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  We conver the image files into single dimension vectors of 28 * 28 * 3
  dimensions
\item
  We will also convert the image classes into integers using the
  following scheme:

  \{'water':0, 'trees':1, 'road':2, 'barren\_land': 3, 'building': 4,
  'grassland':5\}
\end{enumerate}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}1}]:} \PY{k+kn}{import} \PY{n+nn}{cv2}
        \PY{k+kn}{import} \PY{n+nn}{os}
        \PY{k+kn}{from} \PY{n+nn}{custom\PYZus{}dset\PYZus{}new} \PY{k}{import} \PY{n}{train\PYZus{}val\PYZus{}test\PYZus{}split}
        \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
        \PY{k+kn}{from} \PY{n+nn}{tqdm} \PY{k}{import} \PY{n}{tqdm}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{c+c1}{\PYZsh{} set the directory to the image data}
        \PY{n}{data\PYZus{}dir} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{/Users/ruoyangzhang/Documents/PythonWorkingDirectory/Assignment\PYZus{}data/images}\PY{l+s+s1}{\PYZsq{}}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}3}]:} \PY{c+c1}{\PYZsh{} split the dataset into train and test}
        \PY{c+c1}{\PYZsh{} we use the function that we created for the Convolution Neural Net}
        \PY{c+c1}{\PYZsh{} Since there is barely any hyper parameters for with the Random Forest Algorithm, we set val\PYZus{}proportion = 0}
        \PY{n}{train\PYZus{}data}\PY{p}{,} \PY{n}{val\PYZus{}data}\PY{p}{,} \PY{n}{test\PYZus{}data} \PY{o}{=} \PY{n}{train\PYZus{}val\PYZus{}test\PYZus{}split}\PY{p}{(}\PY{n}{data\PYZus{}dir}\PY{p}{,} \PY{n}{train\PYZus{}split}\PY{o}{=}\PY{l+m+mf}{0.8}\PY{p}{,} \PY{n}{val\PYZus{}split}\PY{o}{=}\PY{l+m+mf}{0.0}\PY{p}{,} \PY{n}{test\PYZus{}split} \PY{o}{=} \PY{l+m+mf}{0.2}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}4}]:} \PY{c+c1}{\PYZsh{} additional step to remove unwanted sys files }
        \PY{n}{ordered\PYZus{}train\PYZus{}dirs} \PY{o}{=} \PY{p}{[}\PY{n+nb}{dir} \PY{k}{for} \PY{n+nb}{dir} \PY{o+ow}{in} \PY{n+nb}{sorted}\PY{p}{(}\PY{n+nb}{list}\PY{p}{(}\PY{n}{train\PYZus{}data}\PY{o}{.}\PY{n}{keys}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{)} \PY{k}{if} \PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{split}\PY{p}{(}\PY{n+nb}{dir}\PY{p}{)}\PY{p}{[}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]} \PY{o}{!=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{.DS\PYZus{}Store}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}5}]:} \PY{c+c1}{\PYZsh{} function to convert the images to a vector}
        \PY{k}{def} \PY{n+nf}{convert\PYZus{}to\PYZus{}vector}\PY{p}{(}\PY{n}{img\PYZus{}dir}\PY{p}{)}\PY{p}{:}
            \PY{n}{img} \PY{o}{=} \PY{n}{cv2}\PY{o}{.}\PY{n}{imread}\PY{p}{(}\PY{n}{img\PYZus{}dir}\PY{p}{)}
            \PY{n}{b}\PY{p}{,} \PY{n}{g}\PY{p}{,} \PY{n}{r} \PY{o}{=} \PY{n}{cv2}\PY{o}{.}\PY{n}{split}\PY{p}{(}\PY{n}{img}\PY{p}{)}
            \PY{n}{rgb\PYZus{}img} \PY{o}{=} \PY{n}{cv2}\PY{o}{.}\PY{n}{merge}\PY{p}{(}\PY{p}{[}\PY{n}{r}\PY{p}{,} \PY{n}{g}\PY{p}{,} \PY{n}{b}\PY{p}{]}\PY{p}{)}
            \PY{n}{rgb\PYZus{}img}\PY{o}{.}\PY{n}{shape} \PY{o}{=} \PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{28}\PY{o}{*}\PY{l+m+mi}{28}\PY{o}{*}\PY{l+m+mi}{3}\PY{p}{)}
            \PY{k}{return}\PY{p}{(}\PY{n}{rgb\PYZus{}img}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}6}]:} \PY{c+c1}{\PYZsh{} convert training images to input data}
        \PY{n}{input\PYZus{}images} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{p}{[}\PY{n}{convert\PYZus{}to\PYZus{}vector}\PY{p}{(}\PY{n+nb}{dir}\PY{p}{)} \PY{k}{for} \PY{n+nb}{dir} \PY{o+ow}{in} \PY{n}{tqdm}\PY{p}{(}\PY{n}{ordered\PYZus{}train\PYZus{}dirs}\PY{p}{)}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
100\%|██████████| 259200/259200 [02:10<00:00, 1982.67it/s]

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}7}]:} \PY{c+c1}{\PYZsh{} reshape training input data}
        \PY{n}{input\PYZus{}images}\PY{o}{.}\PY{n}{shape} \PY{o}{=} \PY{p}{(}\PY{n}{input\PYZus{}images}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{n}{input\PYZus{}images}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{2}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}31}]:} \PY{c+c1}{\PYZsh{} construct training input labels}
         \PY{n}{train\PYZus{}labels} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{p}{[}\PY{n}{train\PYZus{}data}\PY{p}{[}\PY{n+nb}{dir}\PY{p}{]} \PY{k}{for} \PY{n+nb}{dir} \PY{o+ow}{in} \PY{n}{ordered\PYZus{}train\PYZus{}dirs}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


    Now we make test data into np.arrays

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}9}]:} \PY{c+c1}{\PYZsh{} additional step to remove unwanted sys files }
        \PY{n}{ordered\PYZus{}test\PYZus{}dirs} \PY{o}{=} \PY{p}{[}\PY{n}{testdir} \PY{k}{for} \PY{n}{testdir} \PY{o+ow}{in} \PY{n+nb}{sorted}\PY{p}{(}\PY{n+nb}{list}\PY{p}{(}\PY{n}{test\PYZus{}data}\PY{o}{.}\PY{n}{keys}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{)} \PY{k}{if} \PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{split}\PY{p}{(}\PY{n}{testdir}\PY{p}{)}\PY{p}{[}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]} \PY{o}{!=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{.DS\PYZus{}Store}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}10}]:} \PY{c+c1}{\PYZsh{} convert testing images to input data}
         \PY{n}{test\PYZus{}images} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{p}{[}\PY{n}{convert\PYZus{}to\PYZus{}vector}\PY{p}{(}\PY{n+nb}{dir}\PY{p}{)} \PY{k}{for} \PY{n+nb}{dir} \PY{o+ow}{in} \PY{n}{tqdm}\PY{p}{(}\PY{n}{ordered\PYZus{}test\PYZus{}dirs}\PY{p}{)}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
100\%|██████████| 64800/64800 [00:36<00:00, 1792.34it/s]

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}11}]:} \PY{c+c1}{\PYZsh{} reshape test input data}
         \PY{n}{test\PYZus{}images}\PY{o}{.}\PY{n}{shape} \PY{o}{=} \PY{p}{(}\PY{n}{test\PYZus{}images}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{n}{test\PYZus{}images}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{2}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}29}]:} \PY{c+c1}{\PYZsh{} construct test input labels}
         \PY{n}{test\PYZus{}labels} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{p}{[}\PY{n}{test\PYZus{}data}\PY{p}{[}\PY{n}{testdir}\PY{p}{]} \PY{k}{for} \PY{n}{testdir} \PY{o+ow}{in} \PY{n}{ordered\PYZus{}test\PYZus{}dirs}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


    \subsection{2. Vanilla Random Forest as a
benchmark}\label{vanilla-random-forest-as-a-benchmark}

    We opt to use the Random Forest algorithm for the particular mission for
the following reasons:

\begin{verbatim}
1. Its robust performance

2. Its lack of hyper parameter tuning, this is vital since the image dataset is large (> 300k images), the training time can be significant and hyperparameter tuning should be minimised given the time constraints

3. It's quick to train

4. Excellent free open source implementation (Sklearn)

5. Simplicity
\end{verbatim}

We note also the disadvantage of the Random Forest algorithm:

\begin{verbatim}
1. Its model size can easily get quite large and evaluation can be relatively slow

2. The lack of interpretability. While decision trees are easy to interpret, a forest is not so much. Random Forest is regarded by some as a blackbox due to the weighting mechanism behind its decisions
\end{verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}13}]:} \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{ensemble} \PY{k}{import} \PY{n}{RandomForestClassifier}
         \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{datasets} \PY{k}{import} \PY{n}{make\PYZus{}classification}
         \PY{k+kn}{from} \PY{n+nn}{sklearn} \PY{k}{import} \PY{n}{metrics}
         \PY{k+kn}{from} \PY{n+nn}{collections} \PY{k}{import} \PY{n}{Counter}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}14}]:} \PY{c+c1}{\PYZsh{} instantiate the classifier}
         \PY{n}{clf} \PY{o}{=} \PY{n}{RandomForestClassifier}\PY{p}{(}\PY{n}{n\PYZus{}estimators}\PY{o}{=}\PY{l+m+mi}{100}\PY{p}{,} \PY{n}{n\PYZus{}jobs} \PY{o}{=} \PY{l+m+mi}{5}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}15}]:} \PY{c+c1}{\PYZsh{} fit the model to the data}
         \PY{n}{clf}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{input\PYZus{}images}\PY{p}{,}\PY{n}{train\PYZus{}labels}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}15}]:} RandomForestClassifier(bootstrap=True, class\_weight=None, criterion='gini',
                     max\_depth=None, max\_features='auto', max\_leaf\_nodes=None,
                     min\_impurity\_decrease=0.0, min\_impurity\_split=None,
                     min\_samples\_leaf=1, min\_samples\_split=2,
                     min\_weight\_fraction\_leaf=0.0, n\_estimators=100, n\_jobs=5,
                     oob\_score=False, random\_state=None, verbose=0,
                     warm\_start=False)
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}16}]:} \PY{c+c1}{\PYZsh{} make predictions}
         \PY{n}{preds} \PY{o}{=} \PY{n}{clf}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{test\PYZus{}images}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}17}]:} \PY{c+c1}{\PYZsh{} evaluate the accuracy}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Accuracy:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{n}{metrics}\PY{o}{.}\PY{n}{accuracy\PYZus{}score}\PY{p}{(}\PY{n}{test\PYZus{}labels}\PY{p}{,} \PY{n}{preds}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Accuracy: 0.966358024691358

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}18}]:} \PY{c+c1}{\PYZsh{} the confusion matrix}
         \PY{n}{metrics}\PY{o}{.}\PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{test\PYZus{}labels}\PY{p}{,} \PY{n}{preds}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}18}]:} array([[24137,     0,     0,     0,     0,     0],
                [   10, 11285,     0,     5,     0,    62],
                [   83,    30,  1282,    26,   134,    44],
                [    1,    44,     0, 14050,    31,   480],
                [   18,     0,    39,     2,  2943,     0],
                [   35,   650,     3,   483,     0,  8923]])
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}19}]:} \PY{c+c1}{\PYZsh{} its precision, recall and fscore in relation to the proportion of each class in the training data}
         
         \PY{n}{bookmark} \PY{o}{=} \PY{p}{\PYZob{}}\PY{l+m+mi}{0}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{precision}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{recall   }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{fscore   }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{support}\PY{l+s+s1}{\PYZsq{}}\PY{p}{\PYZcb{}}
         \PY{n}{class\PYZus{}dict} \PY{o}{=} \PY{p}{\PYZob{}}\PY{l+m+mi}{0}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{water}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{trees}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{road}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{barren\PYZus{}land}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+m+mi}{4}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{building}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+m+mi}{5}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{grassland}\PY{l+s+s1}{\PYZsq{}}\PY{p}{\PYZcb{}}
         \PY{n}{train\PYZus{}class\PYZus{}count} \PY{o}{=} \PY{n}{Counter}\PY{p}{(}\PY{n}{test\PYZus{}data}\PY{o}{.}\PY{n}{values}\PY{p}{(}\PY{p}{)}\PY{p}{)}
         \PY{n}{train\PYZus{}class\PYZus{}balance} \PY{o}{=} \PY{p}{\PYZob{}}\PY{n}{k}\PY{p}{:}\PY{n+nb}{round}\PY{p}{(}\PY{n}{v}\PY{o}{/}\PY{n+nb}{sum}\PY{p}{(}\PY{n}{train\PYZus{}class\PYZus{}count}\PY{o}{.}\PY{n}{values}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{,}\PY{l+m+mi}{4}\PY{p}{)} \PY{k}{for} \PY{n}{k}\PY{p}{,}\PY{n}{v} \PY{o+ow}{in} \PY{n}{train\PYZus{}class\PYZus{}count}\PY{o}{.}\PY{n}{items}\PY{p}{(}\PY{p}{)}\PY{p}{\PYZcb{}}
         
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{, }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{: }\PY{l+s+si}{\PYZob{}:.4f\PYZcb{}}\PY{l+s+s1}{, }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{: }\PY{l+s+si}{\PYZob{}:.4f\PYZcb{}}\PY{l+s+s1}{, }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{: }\PY{l+s+si}{\PYZob{}:.4f\PYZcb{}}\PY{l+s+s1}{, }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{: }\PY{l+s+si}{\PYZob{}:.4f\PYZcb{}}\PY{l+s+s1}{, }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{: }\PY{l+s+si}{\PYZob{}:.4f\PYZcb{}}\PY{l+s+s1}{, }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{: }\PY{l+s+si}{\PYZob{}:.4f\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PYZbs{}
                       \PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{balance  }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                               \PY{n}{class\PYZus{}dict}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{n}{train\PYZus{}class\PYZus{}balance}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,}
                               \PY{n}{class\PYZus{}dict}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{n}{train\PYZus{}class\PYZus{}balance}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,}
                               \PY{n}{class\PYZus{}dict}\PY{p}{[}\PY{l+m+mi}{2}\PY{p}{]}\PY{p}{,} \PY{n}{train\PYZus{}class\PYZus{}balance}\PY{p}{[}\PY{l+m+mi}{2}\PY{p}{]}\PY{p}{,}
                               \PY{n}{class\PYZus{}dict}\PY{p}{[}\PY{l+m+mi}{3}\PY{p}{]}\PY{p}{,} \PY{n}{train\PYZus{}class\PYZus{}balance}\PY{p}{[}\PY{l+m+mi}{3}\PY{p}{]}\PY{p}{,}
                               \PY{n}{class\PYZus{}dict}\PY{p}{[}\PY{l+m+mi}{4}\PY{p}{]}\PY{p}{,} \PY{n}{train\PYZus{}class\PYZus{}balance}\PY{p}{[}\PY{l+m+mi}{4}\PY{p}{]}\PY{p}{,}
                               \PY{n}{class\PYZus{}dict}\PY{p}{[}\PY{l+m+mi}{5}\PY{p}{]}\PY{p}{,} \PY{n}{train\PYZus{}class\PYZus{}balance}\PY{p}{[}\PY{l+m+mi}{5}\PY{p}{]}\PY{p}{)}\PY{p}{)}
         
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         
         \PY{k}{for} \PY{n}{i}\PY{p}{,} \PY{n}{scores} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{metrics}\PY{o}{.}\PY{n}{precision\PYZus{}recall\PYZus{}fscore\PYZus{}support}\PY{p}{(}\PY{n}{test\PYZus{}labels}\PY{p}{,} \PY{n}{preds}\PY{p}{)}\PY{p}{)}\PY{p}{:}
             \PY{k}{if} \PY{n}{i} \PY{o}{\PYZlt{}} \PY{l+m+mi}{3}\PY{p}{:}
                 \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{, }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{: }\PY{l+s+si}{\PYZob{}:.4f\PYZcb{}}\PY{l+s+s1}{, }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{: }\PY{l+s+si}{\PYZob{}:.4f\PYZcb{}}\PY{l+s+s1}{, }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{: }\PY{l+s+si}{\PYZob{}:.4f\PYZcb{}}\PY{l+s+s1}{, }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{: }\PY{l+s+si}{\PYZob{}:.4f\PYZcb{}}\PY{l+s+s1}{, }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{: }\PY{l+s+si}{\PYZob{}:.4f\PYZcb{}}\PY{l+s+s1}{, }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{: }\PY{l+s+si}{\PYZob{}:.4f\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PYZbs{}
                       \PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{bookmark}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{,}
                               \PY{n}{class\PYZus{}dict}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{n}{scores}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,}
                               \PY{n}{class\PYZus{}dict}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{n}{scores}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,}
                               \PY{n}{class\PYZus{}dict}\PY{p}{[}\PY{l+m+mi}{2}\PY{p}{]}\PY{p}{,} \PY{n}{scores}\PY{p}{[}\PY{l+m+mi}{2}\PY{p}{]}\PY{p}{,}
                               \PY{n}{class\PYZus{}dict}\PY{p}{[}\PY{l+m+mi}{3}\PY{p}{]}\PY{p}{,} \PY{n}{scores}\PY{p}{[}\PY{l+m+mi}{3}\PY{p}{]}\PY{p}{,}
                               \PY{n}{class\PYZus{}dict}\PY{p}{[}\PY{l+m+mi}{4}\PY{p}{]}\PY{p}{,} \PY{n}{scores}\PY{p}{[}\PY{l+m+mi}{4}\PY{p}{]}\PY{p}{,}
                               \PY{n}{class\PYZus{}dict}\PY{p}{[}\PY{l+m+mi}{5}\PY{p}{]}\PY{p}{,} \PY{n}{scores}\PY{p}{[}\PY{l+m+mi}{5}\PY{p}{]}\PY{p}{)}\PY{p}{)}
                 \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
balance  , water: 0.3725, trees: 0.1753, road: 0.0247, barren\_land: 0.2254, building: 0.0463, grassland: 0.1558
---------------
precision, water: 0.9939, trees: 0.9397, road: 0.9683, barren\_land: 0.9646, building: 0.9469, grassland: 0.9384
---------------
recall   , water: 1.0000, trees: 0.9932, road: 0.8018, barren\_land: 0.9619, building: 0.9803, grassland: 0.8840
---------------
fscore   , water: 0.9970, trees: 0.9657, road: 0.8772, barren\_land: 0.9633, building: 0.9633, grassland: 0.9104
---------------

    \end{Verbatim}

    As we can tell, we have some evidence to suspect that the class
inbalance is costing us performance. We note the following observations:

\begin{verbatim}
1. the class 'road' is grossly underrepresented in the training set, potentially leading to a low recall score and low overal performance (fscore: 0.8772)

2. curiously, the class 'building', despite being underrepresented in the training set, obtained an acceptable prediction performance, possibly due to its visual distinctiveness

3. on the contrary, the class 'grassland', despite having a relatively fair representation (15.58%), its recall score is below overal performance (fscore: 0.9104), leading us to believe that the class is harder to distinguish from other classes, especially from 'trees' and 'barren_land'
\end{verbatim}

    \subsubsection{Going forward:}\label{going-forward}

The vanilla Random Forest's performance reached a respectable 96.5\%
accuracy with not excellent but acceptable class-wise performance,
notably with minimum engineering.

Going forward, we keep its performance as our baseline benchmark.

We aim to improve the prediction performance of the model by
artifitially balancing out the classes a bit by data augmentation of the
2 worst performing classes:

\begin{verbatim}
1. road: 2
2. grassland: 5
\end{verbatim}

    \subsection{3. Data Augmentation to deal with class
inbalance}\label{data-augmentation-to-deal-with-class-inbalance}

    We have written data augmentation functions (image\_augmentation.py)
which provides the following image transformations:

\begin{verbatim}
1. random rotation between -25 and 25 degrees
2. random rotation between 26 and 75 degrees
3. random rotation either -90 or 90 degrees
4. adding random noise to the data
5. horizontal flip
6. vertical flip
7. transpose
8. zoom (maximum 1.4x)
\end{verbatim}

With the 8 options, we can increase the representation of a particular
class by 8 fold maximum without going into composite transformations

We will try 3 strategies in order to evaluate which data augmentation
gives us the most desired result:

\begin{verbatim}
1. strategy 1
    a. to increase 2 fold the volume of the class 'road'
    b. to increase 2 fold the volume of the class 'grassland'
2. Strategy 2
    a. to increase 4 fold the volume of the class 'road'
    b. to increase 2 fold the volume of the class 'grassland'
3. Strategy 3
    a. to increase 3 fold the volume of the class 'road'
    b. to increase 2 fold the volume of the class 'grassland'
\end{verbatim}

    \subsubsection{Strategy 1}\label{strategy-1}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}108}]:} \PY{k+kn}{from} \PY{n+nn}{image\PYZus{}augmentation} \PY{k}{import} \PY{o}{*}
          
          \PY{c+c1}{\PYZsh{} set fold variables for the 2 classes}
          \PY{n}{class\PYZus{}2\PYZus{}fold} \PY{o}{=} \PY{l+m+mi}{2}
          \PY{n}{class\PYZus{}5\PYZus{}fold} \PY{o}{=} \PY{l+m+mi}{2}
\end{Verbatim}


    We first prep the augmented training data and the respective labels for
class 2 and 5

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}109}]:} \PY{c+c1}{\PYZsh{} we first extract the image\PYZus{}dirs for class 2 \PYZam{} 5}
          \PY{n}{class\PYZus{}2\PYZus{}dirs} \PY{o}{=} \PY{p}{[}\PY{n}{ordered\PYZus{}train\PYZus{}dirs}\PY{p}{[}\PY{n}{i}\PY{p}{]} \PY{k}{for} \PY{n}{i}\PY{p}{,} \PY{n+nb+bp}{cls} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{train\PYZus{}labels}\PY{p}{)} \PY{k}{if} \PY{n+nb+bp}{cls} \PY{o}{==} \PY{l+m+mi}{2}\PY{p}{]}
          \PY{n}{class\PYZus{}2\PYZus{}labels} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{2}\PY{p}{]} \PY{o}{*} \PY{n+nb}{len}\PY{p}{(}\PY{n}{class\PYZus{}2\PYZus{}dirs}\PY{p}{)} \PY{o}{*} \PY{n}{class\PYZus{}2\PYZus{}fold}\PY{p}{)}
          \PY{n}{class\PYZus{}5\PYZus{}dirs} \PY{o}{=} \PY{p}{[}\PY{n}{ordered\PYZus{}train\PYZus{}dirs}\PY{p}{[}\PY{n}{i}\PY{p}{]} \PY{k}{for} \PY{n}{i}\PY{p}{,} \PY{n+nb+bp}{cls} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{train\PYZus{}labels}\PY{p}{)} \PY{k}{if} \PY{n+nb+bp}{cls} \PY{o}{==} \PY{l+m+mi}{5}\PY{p}{]}
          \PY{n}{class\PYZus{}5\PYZus{}labels} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{5}\PY{p}{]} \PY{o}{*} \PY{n+nb}{len}\PY{p}{(}\PY{n}{class\PYZus{}5\PYZus{}dirs}\PY{p}{)} \PY{o}{*} \PY{n}{class\PYZus{}5\PYZus{}fold}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}110}]:} \PY{c+c1}{\PYZsh{} we then augment the data for class 2}
          \PY{n}{augmented\PYZus{}class\PYZus{}2} \PY{o}{=} \PY{n}{image\PYZus{}augmentation}\PY{p}{(}\PY{n}{class\PYZus{}2\PYZus{}dirs}\PY{p}{,} \PY{n}{class\PYZus{}2\PYZus{}fold}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
  2\%|▏         | 146/6593 [00:00<00:08, 723.97it/s]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
the functions to be used for augmentation are: 
1 random\_rotation\_75
2 random\_rotation\_90

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
100\%|██████████| 6593/6593 [00:08<00:00, 807.71it/s]

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}111}]:} \PY{c+c1}{\PYZsh{} we then augment the data for class 5}
          \PY{n}{augmented\PYZus{}class\PYZus{}5} \PY{o}{=} \PY{n}{image\PYZus{}augmentation}\PY{p}{(}\PY{n}{class\PYZus{}5\PYZus{}dirs}\PY{p}{,} \PY{n}{class\PYZus{}5\PYZus{}fold}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
  0\%|          | 195/40253 [00:00<00:41, 970.79it/s]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
the functions to be used for augmentation are: 
1 random\_rotation\_75
2 horizontal\_flip

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
100\%|██████████| 40253/40253 [00:39<00:00, 1024.45it/s]

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}112}]:} \PY{c+c1}{\PYZsh{} new input data and labels}
          \PY{n}{input\PYZus{}images\PYZus{}aug} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{concatenate}\PY{p}{(}\PY{p}{(}\PY{n}{input\PYZus{}images}\PY{p}{,}\PY{n}{augmented\PYZus{}class\PYZus{}2}\PY{p}{,}\PY{n}{augmented\PYZus{}class\PYZus{}5}\PY{p}{)}\PY{p}{,} \PY{n}{axis} \PY{o}{=} \PY{l+m+mi}{0}\PY{p}{)}
          \PY{n}{train\PYZus{}labels\PYZus{}aug} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{concatenate}\PY{p}{(}\PY{p}{(}\PY{n}{train\PYZus{}labels}\PY{p}{,} \PY{n}{class\PYZus{}2\PYZus{}labels}\PY{p}{,} \PY{n}{class\PYZus{}5\PYZus{}labels}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \subsubsection{Strategy 2}\label{strategy-2}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}120}]:} \PY{c+c1}{\PYZsh{} set fold variables for the 2 classes}
          \PY{n}{class\PYZus{}2\PYZus{}fold\PYZus{}2} \PY{o}{=} \PY{l+m+mi}{4}
          \PY{n}{class\PYZus{}5\PYZus{}fold\PYZus{}2} \PY{o}{=} \PY{l+m+mi}{2}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}121}]:} \PY{c+c1}{\PYZsh{} we make the labels for the augmented data for class 2}
          \PY{n}{class\PYZus{}2\PYZus{}labels\PYZus{}2} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{2}\PY{p}{]} \PY{o}{*} \PY{n+nb}{len}\PY{p}{(}\PY{n}{class\PYZus{}2\PYZus{}dirs}\PY{p}{)} \PY{o}{*} \PY{n}{class\PYZus{}2\PYZus{}fold\PYZus{}2}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}123}]:} \PY{c+c1}{\PYZsh{} we then augment the data for class 2}
          \PY{n}{augmented\PYZus{}class\PYZus{}2\PYZus{}2} \PY{o}{=} \PY{n}{image\PYZus{}augmentation}\PY{p}{(}\PY{n}{class\PYZus{}2\PYZus{}dirs}\PY{p}{,} \PY{n}{class\PYZus{}2\PYZus{}fold\PYZus{}2}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
  0\%|          | 0/6593 [00:00<?, ?it/s]/Users/ruoyangzhang/anaconda3/lib/python3.6/site-packages/skimage/transform/\_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.
  warn("The default mode, 'constant', will be changed to 'reflect' in "
  2\%|▏         | 145/6593 [00:00<00:08, 721.27it/s]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
the functions to be used for augmentation are: 
1 vertical\_flip
2 horizontal\_flip
3 random\_rotation\_90
4 zoom

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
100\%|██████████| 6593/6593 [00:09<00:00, 694.62it/s]

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}126}]:} \PY{c+c1}{\PYZsh{} new input data and labels}
          \PY{n}{input\PYZus{}images\PYZus{}aug\PYZus{}2} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{concatenate}\PY{p}{(}\PY{p}{(}\PY{n}{input\PYZus{}images}\PY{p}{,}\PY{n}{augmented\PYZus{}class\PYZus{}2\PYZus{}2}\PY{p}{,}\PY{n}{augmented\PYZus{}class\PYZus{}5}\PY{p}{)}\PY{p}{,} \PY{n}{axis} \PY{o}{=} \PY{l+m+mi}{0}\PY{p}{)}
          \PY{n}{train\PYZus{}labels\PYZus{}aug\PYZus{}2} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{concatenate}\PY{p}{(}\PY{p}{(}\PY{n}{train\PYZus{}labels}\PY{p}{,} \PY{n}{class\PYZus{}2\PYZus{}labels\PYZus{}2}\PY{p}{,} \PY{n}{class\PYZus{}5\PYZus{}labels}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \subsubsection{Strategy 3}\label{strategy-3}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}144}]:} \PY{c+c1}{\PYZsh{} set fold variables for the 2 classes}
          \PY{n}{class\PYZus{}2\PYZus{}fold\PYZus{}3} \PY{o}{=} \PY{l+m+mi}{3}
          \PY{n}{class\PYZus{}5\PYZus{}fold\PYZus{}3} \PY{o}{=} \PY{l+m+mi}{2}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}145}]:} \PY{c+c1}{\PYZsh{} we make the labels for the augmented data for class 2}
          \PY{n}{class\PYZus{}2\PYZus{}labels\PYZus{}3} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{2}\PY{p}{]} \PY{o}{*} \PY{n+nb}{len}\PY{p}{(}\PY{n}{class\PYZus{}2\PYZus{}dirs}\PY{p}{)} \PY{o}{*} \PY{n}{class\PYZus{}2\PYZus{}fold\PYZus{}3}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}146}]:} \PY{c+c1}{\PYZsh{} we then augment the data for class 2}
          \PY{n}{augmented\PYZus{}class\PYZus{}2\PYZus{}3} \PY{o}{=} \PY{n}{image\PYZus{}augmentation}\PY{p}{(}\PY{n}{class\PYZus{}2\PYZus{}dirs}\PY{p}{,} \PY{n}{class\PYZus{}2\PYZus{}fold\PYZus{}3}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
  1\%|          | 40/6593 [00:00<00:16, 399.73it/s]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
the functions to be used for augmentation are: 
1 random\_rotation\_90
2 random\_rotation\_75
3 horizontal\_flip

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
100\%|██████████| 6593/6593 [00:08<00:00, 800.33it/s]

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}149}]:} \PY{c+c1}{\PYZsh{} new input data and labels}
          \PY{n}{input\PYZus{}images\PYZus{}aug\PYZus{}3} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{concatenate}\PY{p}{(}\PY{p}{(}\PY{n}{input\PYZus{}images}\PY{p}{,}\PY{n}{augmented\PYZus{}class\PYZus{}2\PYZus{}3}\PY{p}{,}\PY{n}{augmented\PYZus{}class\PYZus{}5}\PY{p}{)}\PY{p}{,} \PY{n}{axis} \PY{o}{=} \PY{l+m+mi}{0}\PY{p}{)}
          \PY{n}{train\PYZus{}labels\PYZus{}aug\PYZus{}3} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{concatenate}\PY{p}{(}\PY{p}{(}\PY{n}{train\PYZus{}labels}\PY{p}{,} \PY{n}{class\PYZus{}2\PYZus{}labels\PYZus{}3}\PY{p}{,} \PY{n}{class\PYZus{}5\PYZus{}labels}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \subsection{4. Random Forest with augmented
data}\label{random-forest-with-augmented-data}

    \subsubsection{4.1 Strategy 1}\label{strategy-1}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}113}]:} \PY{c+c1}{\PYZsh{} instantiate the classifier}
          \PY{n}{clf\PYZus{}aug} \PY{o}{=} \PY{n}{RandomForestClassifier}\PY{p}{(}\PY{n}{n\PYZus{}estimators}\PY{o}{=}\PY{l+m+mi}{100}\PY{p}{,} \PY{n}{n\PYZus{}jobs} \PY{o}{=} \PY{l+m+mi}{5}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}129}]:} \PY{c+c1}{\PYZsh{} fit the model to the data}
          \PY{n}{clf\PYZus{}aug}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{input\PYZus{}images\PYZus{}aug}\PY{p}{,}\PY{n}{train\PYZus{}labels\PYZus{}aug}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}129}]:} RandomForestClassifier(bootstrap=True, class\_weight=None, criterion='gini',
                      max\_depth=None, max\_features='auto', max\_leaf\_nodes=None,
                      min\_impurity\_decrease=0.0, min\_impurity\_split=None,
                      min\_samples\_leaf=1, min\_samples\_split=2,
                      min\_weight\_fraction\_leaf=0.0, n\_estimators=100, n\_jobs=5,
                      oob\_score=False, random\_state=None, verbose=0,
                      warm\_start=False)
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}130}]:} \PY{c+c1}{\PYZsh{} make predictions}
          \PY{n}{preds\PYZus{}new} \PY{o}{=} \PY{n}{clf\PYZus{}aug}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{test\PYZus{}images}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}131}]:} \PY{c+c1}{\PYZsh{} evaluate the accuracy}
          \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Accuracy:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{n}{metrics}\PY{o}{.}\PY{n}{accuracy\PYZus{}score}\PY{p}{(}\PY{n}{test\PYZus{}labels}\PY{p}{,} \PY{n}{preds\PYZus{}new}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Accuracy: 0.9700308641975308

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}132}]:} \PY{c+c1}{\PYZsh{} the confusion matrix}
          \PY{n}{metrics}\PY{o}{.}\PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{test\PYZus{}labels}\PY{p}{,} \PY{n}{preds\PYZus{}new}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}132}]:} array([[24137,     0,     0,     0,     0,     0],
                 [   10, 11285,     0,     5,     0,    62],
                 [   83,    30,  1282,    26,   134,    44],
                 [    1,    44,     0, 14050,    31,   480],
                 [   18,     0,    39,     2,  2943,     0],
                 [   35,   650,     3,   483,     0,  8923]])
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}136}]:} \PY{c+c1}{\PYZsh{} its precision, recall and fscore in relation to the proportion of each class in the training data}
          
          \PY{n}{bookmark} \PY{o}{=} \PY{p}{\PYZob{}}\PY{l+m+mi}{0}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{precision}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{recall   }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{fscore   }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{support}\PY{l+s+s1}{\PYZsq{}}\PY{p}{\PYZcb{}}
          \PY{n}{class\PYZus{}dict} \PY{o}{=} \PY{p}{\PYZob{}}\PY{l+m+mi}{0}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{water}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{trees}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{road}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{barren\PYZus{}land}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+m+mi}{4}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{building}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+m+mi}{5}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{grassland}\PY{l+s+s1}{\PYZsq{}}\PY{p}{\PYZcb{}}
          \PY{n}{train\PYZus{}class\PYZus{}count\PYZus{}aug} \PY{o}{=} \PY{n}{Counter}\PY{p}{(}\PY{n}{train\PYZus{}labels\PYZus{}aug}\PY{p}{)}
          \PY{n}{train\PYZus{}class\PYZus{}balance\PYZus{}aug} \PY{o}{=} \PY{p}{\PYZob{}}\PY{n}{k}\PY{p}{:}\PY{n+nb}{round}\PY{p}{(}\PY{n}{v}\PY{o}{/}\PY{n+nb}{sum}\PY{p}{(}\PY{n}{train\PYZus{}class\PYZus{}count\PYZus{}aug}\PY{o}{.}\PY{n}{values}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{,}\PY{l+m+mi}{4}\PY{p}{)} \PY{k}{for} \PY{n}{k}\PY{p}{,}\PY{n}{v} \PY{o+ow}{in} \PY{n}{train\PYZus{}class\PYZus{}count\PYZus{}aug}\PY{o}{.}\PY{n}{items}\PY{p}{(}\PY{p}{)}\PY{p}{\PYZcb{}}
          
          \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{, }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{: }\PY{l+s+si}{\PYZob{}:.4f\PYZcb{}}\PY{l+s+s1}{, }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{: }\PY{l+s+si}{\PYZob{}:.4f\PYZcb{}}\PY{l+s+s1}{, }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{: }\PY{l+s+si}{\PYZob{}:.4f\PYZcb{}}\PY{l+s+s1}{, }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{: }\PY{l+s+si}{\PYZob{}:.4f\PYZcb{}}\PY{l+s+s1}{, }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{: }\PY{l+s+si}{\PYZob{}:.4f\PYZcb{}}\PY{l+s+s1}{, }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{: }\PY{l+s+si}{\PYZob{}:.4f\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PYZbs{}
                        \PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{balance  }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                                \PY{n}{class\PYZus{}dict}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{n}{train\PYZus{}class\PYZus{}balance\PYZus{}aug}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,}
                                \PY{n}{class\PYZus{}dict}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{n}{train\PYZus{}class\PYZus{}balance\PYZus{}aug}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,}
                                \PY{n}{class\PYZus{}dict}\PY{p}{[}\PY{l+m+mi}{2}\PY{p}{]}\PY{p}{,} \PY{n}{train\PYZus{}class\PYZus{}balance\PYZus{}aug}\PY{p}{[}\PY{l+m+mi}{2}\PY{p}{]}\PY{p}{,}
                                \PY{n}{class\PYZus{}dict}\PY{p}{[}\PY{l+m+mi}{3}\PY{p}{]}\PY{p}{,} \PY{n}{train\PYZus{}class\PYZus{}balance\PYZus{}aug}\PY{p}{[}\PY{l+m+mi}{3}\PY{p}{]}\PY{p}{,}
                                \PY{n}{class\PYZus{}dict}\PY{p}{[}\PY{l+m+mi}{4}\PY{p}{]}\PY{p}{,} \PY{n}{train\PYZus{}class\PYZus{}balance\PYZus{}aug}\PY{p}{[}\PY{l+m+mi}{4}\PY{p}{]}\PY{p}{,}
                                \PY{n}{class\PYZus{}dict}\PY{p}{[}\PY{l+m+mi}{5}\PY{p}{]}\PY{p}{,} \PY{n}{train\PYZus{}class\PYZus{}balance\PYZus{}aug}\PY{p}{[}\PY{l+m+mi}{5}\PY{p}{]}\PY{p}{)}\PY{p}{)}
          
          \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          
          \PY{k}{for} \PY{n}{i}\PY{p}{,} \PY{n}{scores} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{metrics}\PY{o}{.}\PY{n}{precision\PYZus{}recall\PYZus{}fscore\PYZus{}support}\PY{p}{(}\PY{n}{test\PYZus{}labels}\PY{p}{,} \PY{n}{preds\PYZus{}new}\PY{p}{)}\PY{p}{)}\PY{p}{:}
              \PY{k}{if} \PY{n}{i} \PY{o}{\PYZlt{}} \PY{l+m+mi}{3}\PY{p}{:}
                  \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{, }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{: }\PY{l+s+si}{\PYZob{}:.4f\PYZcb{}}\PY{l+s+s1}{, }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{: }\PY{l+s+si}{\PYZob{}:.4f\PYZcb{}}\PY{l+s+s1}{, }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{: }\PY{l+s+si}{\PYZob{}:.4f\PYZcb{}}\PY{l+s+s1}{, }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{: }\PY{l+s+si}{\PYZob{}:.4f\PYZcb{}}\PY{l+s+s1}{, }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{: }\PY{l+s+si}{\PYZob{}:.4f\PYZcb{}}\PY{l+s+s1}{, }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{: }\PY{l+s+si}{\PYZob{}:.4f\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PYZbs{}
                        \PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{bookmark}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{,}
                                \PY{n}{class\PYZus{}dict}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{n}{scores}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,}
                                \PY{n}{class\PYZus{}dict}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{n}{scores}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,}
                                \PY{n}{class\PYZus{}dict}\PY{p}{[}\PY{l+m+mi}{2}\PY{p}{]}\PY{p}{,} \PY{n}{scores}\PY{p}{[}\PY{l+m+mi}{2}\PY{p}{]}\PY{p}{,}
                                \PY{n}{class\PYZus{}dict}\PY{p}{[}\PY{l+m+mi}{3}\PY{p}{]}\PY{p}{,} \PY{n}{scores}\PY{p}{[}\PY{l+m+mi}{3}\PY{p}{]}\PY{p}{,}
                                \PY{n}{class\PYZus{}dict}\PY{p}{[}\PY{l+m+mi}{4}\PY{p}{]}\PY{p}{,} \PY{n}{scores}\PY{p}{[}\PY{l+m+mi}{4}\PY{p}{]}\PY{p}{,}
                                \PY{n}{class\PYZus{}dict}\PY{p}{[}\PY{l+m+mi}{5}\PY{p}{]}\PY{p}{,} \PY{n}{scores}\PY{p}{[}\PY{l+m+mi}{5}\PY{p}{]}\PY{p}{)}\PY{p}{)}
                  \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
balance  , water: 0.2726, trees: 0.1288, road: 0.0560, barren\_land: 0.1666, building: 0.0338, grassland: 0.3422
---------------
precision, water: 0.9946, trees: 0.9669, road: 0.9709, barren\_land: 0.9823, building: 0.9463, grassland: 0.9072
---------------
recall   , water: 1.0000, trees: 0.9843, road: 0.7724, barren\_land: 0.9460, building: 0.9800, grassland: 0.9453
---------------
fscore   , water: 0.9973, trees: 0.9755, road: 0.8603, barren\_land: 0.9638, building: 0.9629, grassland: 0.9259
---------------

    \end{Verbatim}

    \subsubsection{4.2 Strategy 2}\label{strategy-2}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}137}]:} \PY{c+c1}{\PYZsh{} instantiate the classifier}
          \PY{n}{clf\PYZus{}aug\PYZus{}2} \PY{o}{=} \PY{n}{RandomForestClassifier}\PY{p}{(}\PY{n}{n\PYZus{}estimators}\PY{o}{=}\PY{l+m+mi}{100}\PY{p}{,} \PY{n}{n\PYZus{}jobs} \PY{o}{=} \PY{l+m+mi}{5}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}139}]:} \PY{c+c1}{\PYZsh{} fit the model to the data}
          \PY{n}{clf\PYZus{}aug\PYZus{}2}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{input\PYZus{}images\PYZus{}aug\PYZus{}2}\PY{p}{,}\PY{n}{train\PYZus{}labels\PYZus{}aug\PYZus{}2}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}139}]:} RandomForestClassifier(bootstrap=True, class\_weight=None, criterion='gini',
                      max\_depth=None, max\_features='auto', max\_leaf\_nodes=None,
                      min\_impurity\_decrease=0.0, min\_impurity\_split=None,
                      min\_samples\_leaf=1, min\_samples\_split=2,
                      min\_weight\_fraction\_leaf=0.0, n\_estimators=100, n\_jobs=5,
                      oob\_score=False, random\_state=None, verbose=0,
                      warm\_start=False)
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}140}]:} \PY{c+c1}{\PYZsh{} make predictions}
          \PY{n}{preds\PYZus{}new\PYZus{}2} \PY{o}{=} \PY{n}{clf\PYZus{}aug\PYZus{}2}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{test\PYZus{}images}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}141}]:} \PY{c+c1}{\PYZsh{} evaluate the accuracy}
          \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Accuracy:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{n}{metrics}\PY{o}{.}\PY{n}{accuracy\PYZus{}score}\PY{p}{(}\PY{n}{test\PYZus{}labels}\PY{p}{,} \PY{n}{preds\PYZus{}new\PYZus{}2}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Accuracy: 0.9695370370370371

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}142}]:} \PY{c+c1}{\PYZsh{} the confusion matrix}
          \PY{n}{metrics}\PY{o}{.}\PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{test\PYZus{}labels}\PY{p}{,} \PY{n}{preds\PYZus{}new\PYZus{}2}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}142}]:} array([[24136,     0,     1,     0,     0,     0],
                 [   14, 11182,     1,     2,     0,   163],
                 [   42,    28,  1455,     8,    35,    31],
                 [    1,    40,    13, 13828,    23,   701],
                 [    5,     1,   291,     1,  2702,     2],
                 [   18,   326,     6,   221,     0,  9523]])
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}143}]:} \PY{c+c1}{\PYZsh{} its precision, recall and fscore in relation to the proportion of each class in the training data}
          
          \PY{n}{bookmark} \PY{o}{=} \PY{p}{\PYZob{}}\PY{l+m+mi}{0}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{precision}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{recall   }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{fscore   }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{support}\PY{l+s+s1}{\PYZsq{}}\PY{p}{\PYZcb{}}
          \PY{n}{class\PYZus{}dict} \PY{o}{=} \PY{p}{\PYZob{}}\PY{l+m+mi}{0}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{water}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{trees}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{road}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{barren\PYZus{}land}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+m+mi}{4}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{building}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+m+mi}{5}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{grassland}\PY{l+s+s1}{\PYZsq{}}\PY{p}{\PYZcb{}}
          \PY{n}{train\PYZus{}class\PYZus{}count\PYZus{}aug\PYZus{}2} \PY{o}{=} \PY{n}{Counter}\PY{p}{(}\PY{n}{train\PYZus{}labels\PYZus{}aug\PYZus{}2}\PY{p}{)}
          \PY{n}{train\PYZus{}class\PYZus{}balance\PYZus{}aug\PYZus{}2} \PY{o}{=} \PY{p}{\PYZob{}}\PY{n}{k}\PY{p}{:}\PY{n+nb}{round}\PY{p}{(}\PY{n}{v}\PY{o}{/}\PY{n+nb}{sum}\PY{p}{(}\PY{n}{train\PYZus{}class\PYZus{}count\PYZus{}aug\PYZus{}2}\PY{o}{.}\PY{n}{values}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{,}\PY{l+m+mi}{4}\PY{p}{)} \PY{k}{for} \PY{n}{k}\PY{p}{,}\PY{n}{v} \PY{o+ow}{in} \PY{n}{train\PYZus{}class\PYZus{}count\PYZus{}aug\PYZus{}2}\PY{o}{.}\PY{n}{items}\PY{p}{(}\PY{p}{)}\PY{p}{\PYZcb{}}
          
          \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{, }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{: }\PY{l+s+si}{\PYZob{}:.4f\PYZcb{}}\PY{l+s+s1}{, }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{: }\PY{l+s+si}{\PYZob{}:.4f\PYZcb{}}\PY{l+s+s1}{, }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{: }\PY{l+s+si}{\PYZob{}:.4f\PYZcb{}}\PY{l+s+s1}{, }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{: }\PY{l+s+si}{\PYZob{}:.4f\PYZcb{}}\PY{l+s+s1}{, }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{: }\PY{l+s+si}{\PYZob{}:.4f\PYZcb{}}\PY{l+s+s1}{, }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{: }\PY{l+s+si}{\PYZob{}:.4f\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PYZbs{}
                        \PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{balance  }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                                \PY{n}{class\PYZus{}dict}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{n}{train\PYZus{}class\PYZus{}balance\PYZus{}aug\PYZus{}2}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,}
                                \PY{n}{class\PYZus{}dict}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{n}{train\PYZus{}class\PYZus{}balance\PYZus{}aug\PYZus{}2}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,}
                                \PY{n}{class\PYZus{}dict}\PY{p}{[}\PY{l+m+mi}{2}\PY{p}{]}\PY{p}{,} \PY{n}{train\PYZus{}class\PYZus{}balance\PYZus{}aug\PYZus{}2}\PY{p}{[}\PY{l+m+mi}{2}\PY{p}{]}\PY{p}{,}
                                \PY{n}{class\PYZus{}dict}\PY{p}{[}\PY{l+m+mi}{3}\PY{p}{]}\PY{p}{,} \PY{n}{train\PYZus{}class\PYZus{}balance\PYZus{}aug\PYZus{}2}\PY{p}{[}\PY{l+m+mi}{3}\PY{p}{]}\PY{p}{,}
                                \PY{n}{class\PYZus{}dict}\PY{p}{[}\PY{l+m+mi}{4}\PY{p}{]}\PY{p}{,} \PY{n}{train\PYZus{}class\PYZus{}balance\PYZus{}aug\PYZus{}2}\PY{p}{[}\PY{l+m+mi}{4}\PY{p}{]}\PY{p}{,}
                                \PY{n}{class\PYZus{}dict}\PY{p}{[}\PY{l+m+mi}{5}\PY{p}{]}\PY{p}{,} \PY{n}{train\PYZus{}class\PYZus{}balance\PYZus{}aug\PYZus{}2}\PY{p}{[}\PY{l+m+mi}{5}\PY{p}{]}\PY{p}{)}\PY{p}{)}
          
          \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          
          \PY{k}{for} \PY{n}{i}\PY{p}{,} \PY{n}{scores} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{metrics}\PY{o}{.}\PY{n}{precision\PYZus{}recall\PYZus{}fscore\PYZus{}support}\PY{p}{(}\PY{n}{test\PYZus{}labels}\PY{p}{,} \PY{n}{preds\PYZus{}new\PYZus{}2}\PY{p}{)}\PY{p}{)}\PY{p}{:}
              \PY{k}{if} \PY{n}{i} \PY{o}{\PYZlt{}} \PY{l+m+mi}{3}\PY{p}{:}
                  \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{, }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{: }\PY{l+s+si}{\PYZob{}:.4f\PYZcb{}}\PY{l+s+s1}{, }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{: }\PY{l+s+si}{\PYZob{}:.4f\PYZcb{}}\PY{l+s+s1}{, }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{: }\PY{l+s+si}{\PYZob{}:.4f\PYZcb{}}\PY{l+s+s1}{, }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{: }\PY{l+s+si}{\PYZob{}:.4f\PYZcb{}}\PY{l+s+s1}{, }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{: }\PY{l+s+si}{\PYZob{}:.4f\PYZcb{}}\PY{l+s+s1}{, }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{: }\PY{l+s+si}{\PYZob{}:.4f\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PYZbs{}
                        \PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{bookmark}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{,}
                                \PY{n}{class\PYZus{}dict}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{n}{scores}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,}
                                \PY{n}{class\PYZus{}dict}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{n}{scores}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,}
                                \PY{n}{class\PYZus{}dict}\PY{p}{[}\PY{l+m+mi}{2}\PY{p}{]}\PY{p}{,} \PY{n}{scores}\PY{p}{[}\PY{l+m+mi}{2}\PY{p}{]}\PY{p}{,}
                                \PY{n}{class\PYZus{}dict}\PY{p}{[}\PY{l+m+mi}{3}\PY{p}{]}\PY{p}{,} \PY{n}{scores}\PY{p}{[}\PY{l+m+mi}{3}\PY{p}{]}\PY{p}{,}
                                \PY{n}{class\PYZus{}dict}\PY{p}{[}\PY{l+m+mi}{4}\PY{p}{]}\PY{p}{,} \PY{n}{scores}\PY{p}{[}\PY{l+m+mi}{4}\PY{p}{]}\PY{p}{,}
                                \PY{n}{class\PYZus{}dict}\PY{p}{[}\PY{l+m+mi}{5}\PY{p}{]}\PY{p}{,} \PY{n}{scores}\PY{p}{[}\PY{l+m+mi}{5}\PY{p}{]}\PY{p}{)}\PY{p}{)}
                  \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
balance  , water: 0.2628, trees: 0.1241, road: 0.0900, barren\_land: 0.1606, building: 0.0326, grassland: 0.3299
---------------
precision, water: 0.9967, trees: 0.9659, road: 0.8234, barren\_land: 0.9835, building: 0.9790, grassland: 0.9139
---------------
recall   , water: 1.0000, trees: 0.9842, road: 0.9099, barren\_land: 0.9467, building: 0.9001, grassland: 0.9434
---------------
fscore   , water: 0.9983, trees: 0.9749, road: 0.8645, barren\_land: 0.9648, building: 0.9379, grassland: 0.9284
---------------

    \end{Verbatim}

    \subsubsection{4.3 Strategy 3}\label{strategy-3}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}150}]:} \PY{c+c1}{\PYZsh{} instantiate the classifier}
          \PY{n}{clf\PYZus{}aug\PYZus{}3} \PY{o}{=} \PY{n}{RandomForestClassifier}\PY{p}{(}\PY{n}{n\PYZus{}estimators}\PY{o}{=}\PY{l+m+mi}{100}\PY{p}{,} \PY{n}{n\PYZus{}jobs} \PY{o}{=} \PY{l+m+mi}{5}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}152}]:} \PY{c+c1}{\PYZsh{} fit the model to the data}
          \PY{n}{clf\PYZus{}aug\PYZus{}3}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{input\PYZus{}images\PYZus{}aug\PYZus{}3}\PY{p}{,}\PY{n}{train\PYZus{}labels\PYZus{}aug\PYZus{}3}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}152}]:} RandomForestClassifier(bootstrap=True, class\_weight=None, criterion='gini',
                      max\_depth=None, max\_features='auto', max\_leaf\_nodes=None,
                      min\_impurity\_decrease=0.0, min\_impurity\_split=None,
                      min\_samples\_leaf=1, min\_samples\_split=2,
                      min\_weight\_fraction\_leaf=0.0, n\_estimators=100, n\_jobs=5,
                      oob\_score=False, random\_state=None, verbose=0,
                      warm\_start=False)
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}153}]:} \PY{c+c1}{\PYZsh{} make predictions}
          \PY{n}{preds\PYZus{}new\PYZus{}3} \PY{o}{=} \PY{n}{clf\PYZus{}aug\PYZus{}3}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{test\PYZus{}images}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}154}]:} \PY{c+c1}{\PYZsh{} evaluate the accuracy}
          \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Accuracy:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{n}{metrics}\PY{o}{.}\PY{n}{accuracy\PYZus{}score}\PY{p}{(}\PY{n}{test\PYZus{}labels}\PY{p}{,} \PY{n}{preds\PYZus{}new\PYZus{}3}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Accuracy: 0.9702006172839506

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}155}]:} \PY{c+c1}{\PYZsh{} the confusion matrix}
          \PY{n}{metrics}\PY{o}{.}\PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{test\PYZus{}labels}\PY{p}{,} \PY{n}{preds\PYZus{}new\PYZus{}3}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}155}]:} array([[24137,     0,     0,     0,     0,     0],
                 [   16, 11183,     0,     1,     0,   162],
                 [   50,    30,  1395,    10,    57,    57],
                 [    1,    42,    10, 13817,    23,   713],
                 [   15,     0,   170,     1,  2814,     2],
                 [   17,   327,     4,   223,     0,  9523]])
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}156}]:} \PY{c+c1}{\PYZsh{} its precision, recall and fscore in relation to the proportion of each class in the training data}
          
          \PY{n}{bookmark} \PY{o}{=} \PY{p}{\PYZob{}}\PY{l+m+mi}{0}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{precision}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{recall   }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{fscore   }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{support}\PY{l+s+s1}{\PYZsq{}}\PY{p}{\PYZcb{}}
          \PY{n}{class\PYZus{}dict} \PY{o}{=} \PY{p}{\PYZob{}}\PY{l+m+mi}{0}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{water}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{trees}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{road}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{barren\PYZus{}land}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+m+mi}{4}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{building}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+m+mi}{5}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{grassland}\PY{l+s+s1}{\PYZsq{}}\PY{p}{\PYZcb{}}
          \PY{n}{train\PYZus{}class\PYZus{}count\PYZus{}aug\PYZus{}3} \PY{o}{=} \PY{n}{Counter}\PY{p}{(}\PY{n}{train\PYZus{}labels\PYZus{}aug\PYZus{}3}\PY{p}{)}
          \PY{n}{train\PYZus{}class\PYZus{}balance\PYZus{}aug\PYZus{}3} \PY{o}{=} \PY{p}{\PYZob{}}\PY{n}{k}\PY{p}{:}\PY{n+nb}{round}\PY{p}{(}\PY{n}{v}\PY{o}{/}\PY{n+nb}{sum}\PY{p}{(}\PY{n}{train\PYZus{}class\PYZus{}count\PYZus{}aug\PYZus{}3}\PY{o}{.}\PY{n}{values}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{,}\PY{l+m+mi}{4}\PY{p}{)} \PY{k}{for} \PY{n}{k}\PY{p}{,}\PY{n}{v} \PY{o+ow}{in} \PY{n}{train\PYZus{}class\PYZus{}count\PYZus{}aug\PYZus{}3}\PY{o}{.}\PY{n}{items}\PY{p}{(}\PY{p}{)}\PY{p}{\PYZcb{}}
          
          \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{, }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{: }\PY{l+s+si}{\PYZob{}:.4f\PYZcb{}}\PY{l+s+s1}{, }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{: }\PY{l+s+si}{\PYZob{}:.4f\PYZcb{}}\PY{l+s+s1}{, }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{: }\PY{l+s+si}{\PYZob{}:.4f\PYZcb{}}\PY{l+s+s1}{, }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{: }\PY{l+s+si}{\PYZob{}:.4f\PYZcb{}}\PY{l+s+s1}{, }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{: }\PY{l+s+si}{\PYZob{}:.4f\PYZcb{}}\PY{l+s+s1}{, }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{: }\PY{l+s+si}{\PYZob{}:.4f\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PYZbs{}
                        \PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{balance  }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                                \PY{n}{class\PYZus{}dict}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{n}{train\PYZus{}class\PYZus{}balance\PYZus{}aug\PYZus{}3}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,}
                                \PY{n}{class\PYZus{}dict}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{n}{train\PYZus{}class\PYZus{}balance\PYZus{}aug\PYZus{}3}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,}
                                \PY{n}{class\PYZus{}dict}\PY{p}{[}\PY{l+m+mi}{2}\PY{p}{]}\PY{p}{,} \PY{n}{train\PYZus{}class\PYZus{}balance\PYZus{}aug\PYZus{}3}\PY{p}{[}\PY{l+m+mi}{2}\PY{p}{]}\PY{p}{,}
                                \PY{n}{class\PYZus{}dict}\PY{p}{[}\PY{l+m+mi}{3}\PY{p}{]}\PY{p}{,} \PY{n}{train\PYZus{}class\PYZus{}balance\PYZus{}aug\PYZus{}3}\PY{p}{[}\PY{l+m+mi}{3}\PY{p}{]}\PY{p}{,}
                                \PY{n}{class\PYZus{}dict}\PY{p}{[}\PY{l+m+mi}{4}\PY{p}{]}\PY{p}{,} \PY{n}{train\PYZus{}class\PYZus{}balance\PYZus{}aug\PYZus{}3}\PY{p}{[}\PY{l+m+mi}{4}\PY{p}{]}\PY{p}{,}
                                \PY{n}{class\PYZus{}dict}\PY{p}{[}\PY{l+m+mi}{5}\PY{p}{]}\PY{p}{,} \PY{n}{train\PYZus{}class\PYZus{}balance\PYZus{}aug\PYZus{}3}\PY{p}{[}\PY{l+m+mi}{5}\PY{p}{]}\PY{p}{)}\PY{p}{)}
          
          \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          
          \PY{k}{for} \PY{n}{i}\PY{p}{,} \PY{n}{scores} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{metrics}\PY{o}{.}\PY{n}{precision\PYZus{}recall\PYZus{}fscore\PYZus{}support}\PY{p}{(}\PY{n}{test\PYZus{}labels}\PY{p}{,} \PY{n}{preds\PYZus{}new\PYZus{}3}\PY{p}{)}\PY{p}{)}\PY{p}{:}
              \PY{k}{if} \PY{n}{i} \PY{o}{\PYZlt{}} \PY{l+m+mi}{3}\PY{p}{:}
                  \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{, }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{: }\PY{l+s+si}{\PYZob{}:.4f\PYZcb{}}\PY{l+s+s1}{, }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{: }\PY{l+s+si}{\PYZob{}:.4f\PYZcb{}}\PY{l+s+s1}{, }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{: }\PY{l+s+si}{\PYZob{}:.4f\PYZcb{}}\PY{l+s+s1}{, }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{: }\PY{l+s+si}{\PYZob{}:.4f\PYZcb{}}\PY{l+s+s1}{, }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{: }\PY{l+s+si}{\PYZob{}:.4f\PYZcb{}}\PY{l+s+s1}{, }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{: }\PY{l+s+si}{\PYZob{}:.4f\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PYZbs{}
                        \PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{bookmark}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{,}
                                \PY{n}{class\PYZus{}dict}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{n}{scores}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,}
                                \PY{n}{class\PYZus{}dict}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{n}{scores}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,}
                                \PY{n}{class\PYZus{}dict}\PY{p}{[}\PY{l+m+mi}{2}\PY{p}{]}\PY{p}{,} \PY{n}{scores}\PY{p}{[}\PY{l+m+mi}{2}\PY{p}{]}\PY{p}{,}
                                \PY{n}{class\PYZus{}dict}\PY{p}{[}\PY{l+m+mi}{3}\PY{p}{]}\PY{p}{,} \PY{n}{scores}\PY{p}{[}\PY{l+m+mi}{3}\PY{p}{]}\PY{p}{,}
                                \PY{n}{class\PYZus{}dict}\PY{p}{[}\PY{l+m+mi}{4}\PY{p}{]}\PY{p}{,} \PY{n}{scores}\PY{p}{[}\PY{l+m+mi}{4}\PY{p}{]}\PY{p}{,}
                                \PY{n}{class\PYZus{}dict}\PY{p}{[}\PY{l+m+mi}{5}\PY{p}{]}\PY{p}{,} \PY{n}{scores}\PY{p}{[}\PY{l+m+mi}{5}\PY{p}{]}\PY{p}{)}\PY{p}{)}
                  \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
balance  , water: 0.2676, trees: 0.1264, road: 0.0734, barren\_land: 0.1635, building: 0.0332, grassland: 0.3359
---------------
precision, water: 0.9959, trees: 0.9655, road: 0.8835, barren\_land: 0.9833, building: 0.9724, grassland: 0.9107
---------------
recall   , water: 1.0000, trees: 0.9842, road: 0.8724, barren\_land: 0.9460, building: 0.9374, grassland: 0.9434
---------------
fscore   , water: 0.9980, trees: 0.9748, road: 0.8779, barren\_land: 0.9643, building: 0.9545, grassland: 0.9268
---------------

    \end{Verbatim}

    \subsubsection{4.3 Discussion}\label{discussion}

    In resume, we have trained 4 models with different data augmentations
with the following accuracy performance:

Original Vanilla Model: 0.9664

Model of strategy 1 : 0.9700

Model of strategy 2 : 0.9695

Model of strategy 3 : 0.9702

We can see a minor increase in model accuracy after various degrees of
data augmentation. From an accuracy's point of view, the data augmented
models are generally superior.

However, we know that accuracy is not a very holistic metric in
evaluating a model's performance. We have noted previously that :

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  the original model's performance was skewed towards classes with large
  sample sizes
\item
  the original model's precision/recall balance was weak for the
  aforementioned classes: 2 \& 5
\end{enumerate}

This is when the data augmented models performed quite differently:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  model of strategy 1 performed poorly for class 2 and 5, with class 2's
  precision (0.9709) being largely superior than its recall (0.7724)
\item
  model of strategy 2 had a similar problem with the precision of class
  2 (0.8234) being largely inferior to its recall (0.9099)
\item
  model of strategy 3's class-wise precision-recall balance is fairly
  well upheld
\end{enumerate}

Overall, the original model not only lacked in accuracy, it also had
class-wise performance inbalance (measured in fscore). The data
augmented models performed better in that regard, but model 1 and 2 both
had precision-recall balance issues for class 2, whereas model 3
achieved a relatively good level of balance, both in terms of class-wise
performance and class-wise precision-recall balance.

    \subsection{5. Performance comparison with CNN using pretrained
InceptionV3}\label{performance-comparison-with-cnn-using-pretrained-inceptionv3}

    \subsubsection{5.1 The CNN Architecture}\label{the-cnn-architecture}

    We applied the transfer learning technique to avoid retrainning the
model from scratch. We used the pretrained InceptionV3 model provided by
the PyTorch framework for the following reasons: 1. Its relative light
weight for training in comparison with other popular architectures such
as Resnet or VGG 2. Its availability in torch.vision (there are other
light architectures such as mobilenet but they are not readily available
in torch.vision) 3. Its rebust performance

    We trained multiple models using this architecture:

Shared variables:

Optimisation: SGD

Loss Function: Cross Entropy

Batchsize: 32

Group 1, 8 training epochs: 1. fully connected layers unfrozen, decaying
learning rate 1e-3, step size = 7, gamma = 0.1 2. layers after
'Conv2d\_4a\_3x3' unfrozen, decaying learning rate 1e-3, step size = 7,
gamma = 0.1 Group 2, 5 training epochs: 1. fully connected layers
unfrozen \& decaying learning rate 1e-5, step size = 3, gamma = 0.2 2.
layers after 'Conv2d\_4a\_3x3' unfrozen, decaying learning rate 1e-5,
step size = 3, gamma = 0.2

    Group 2 performed better on the validation set with considerably less
training data:

Best alidation accuracy:

\begin{verbatim}
Group 1:
    1. 0.8789
    2. 0.8827
Group 2:
    1. 0.9043
    2. 0.9156   
\end{verbatim}

    We finally kept the 2nd model from group 2.

We chose not to further tune the hyper parameter or run any more epochs
since the Random Forest algorithm provides a much superior performance
in terms of accuracy.

    \paragraph{Due to training being interrupted half way, the model not the
testing data was not succesfully saved, please find below a proof of the
best performing model (group 2 model 2)'s validation performing during
training}\label{due-to-training-being-interrupted-half-way-the-model-not-the-testing-data-was-not-succesfully-saved-please-find-below-a-proof-of-the-best-performing-model-group-2-model-2s-validation-performing-during-training}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}10}]:} \PY{k+kn}{from} \PY{n+nn}{IPython}\PY{n+nn}{.}\PY{n+nn}{display} \PY{k}{import} \PY{n}{Image}
         \PY{n}{Image}\PY{p}{(}\PY{n}{filename}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Screenshot.png}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}

\texttt{\color{outcolor}Out[{\color{outcolor}10}]:}
    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_78_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    

    \subsection{6. Conclusions}\label{conclusions}

    \paragraph{In conclusion, model from strategy 3 is the most desirable
model}\label{in-conclusion-model-from-strategy-3-is-the-most-desirable-model}

Model description:

Algorithm: Random Forest (SkLearn implementation)

Number of estimators: 100

Data Augmentation: 3 fold data augmentation of class 2 (road): 1.
random\_rotation\_90 2. random\_rotation\_75 3. horizontal\_flip

2 fold data augmentation of class 5 (grassland): 1. random\_rotation\_75
2. horizontal\_flip

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

The model performed well with an \textbf{accuray of 0.9702} with minimum
class-wise performance inbalance.

Class-wise precision, recall and fscore:

\textbf{precision}, \emph{water}: 0.9959, \emph{trees}: 0.9655,
\emph{road}: 0.8835, \emph{barren\_land}: 0.9833, \emph{building}:
0.9724, \emph{grassland}: 0.9107

\textbf{recall} , \emph{water}: 1.0000, \emph{trees}: 0.9842,
\emph{road}: 0.8724, \emph{barren\_land}: 0.9460, \emph{building}:
0.9374, \emph{grassland}: 0.9434

\textbf{fscore} , \emph{water}: 0.9980, \emph{trees}: 0.9748,
\emph{road}: 0.8779, \emph{barren\_land}: 0.9643, \emph{building}:
0.9545, \emph{grassland}: 0.9268

    \subsection{7. Appendix - all functions and classes contained in
seperate .py
files}\label{appendix---all-functions-and-classes-contained-in-seperate-.py-files}

    \subsubsection{7.1 image\_augmentation.py}\label{image_augmentation.py}

function used in the code above to perform image data augmentation

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}11}]:} \PY{k+kn}{import} \PY{n+nn}{random}
         \PY{k+kn}{from} \PY{n+nn}{scipy} \PY{k}{import} \PY{n}{ndarray}
         \PY{k+kn}{import} \PY{n+nn}{skimage} \PY{k}{as} \PY{n+nn}{sk}
         \PY{k+kn}{from} \PY{n+nn}{skimage} \PY{k}{import} \PY{n}{util}
         \PY{k+kn}{from} \PY{n+nn}{math} \PY{k}{import} \PY{n}{floor}
         \PY{k+kn}{import} \PY{n+nn}{cv2}
         \PY{k+kn}{from} \PY{n+nn}{tqdm} \PY{k}{import} \PY{n}{tqdm}
         \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
         
         
         \PY{k}{def} \PY{n+nf}{random\PYZus{}rotation\PYZus{}25}\PY{p}{(}\PY{n}{image\PYZus{}array}\PY{p}{:} \PY{n}{ndarray}\PY{p}{)}\PY{p}{:}
             \PY{c+c1}{\PYZsh{} pick a random degree of rotation between 25 on the left and 25 degrees on the right}
             \PY{n}{random\PYZus{}degree} \PY{o}{=} \PY{n}{random}\PY{o}{.}\PY{n}{uniform}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{25}\PY{p}{,} \PY{l+m+mi}{25}\PY{p}{)}
             \PY{k}{return}\PY{p}{(}\PY{n}{sk}\PY{o}{.}\PY{n}{transform}\PY{o}{.}\PY{n}{rotate}\PY{p}{(}\PY{n}{image\PYZus{}array}\PY{p}{,} \PY{n}{random\PYZus{}degree}\PY{p}{)}\PY{p}{)}
         
         \PY{k}{def} \PY{n+nf}{random\PYZus{}rotation\PYZus{}75}\PY{p}{(}\PY{n}{image\PYZus{}array}\PY{p}{:} \PY{n}{ndarray}\PY{p}{)}\PY{p}{:}
             \PY{c+c1}{\PYZsh{} pick a random degree of rotation between 26 on the right and 75 degrees on the right}
             \PY{n}{random\PYZus{}degree} \PY{o}{=} \PY{n}{random}\PY{o}{.}\PY{n}{uniform}\PY{p}{(}\PY{l+m+mi}{26}\PY{p}{,} \PY{l+m+mi}{75}\PY{p}{)}
             \PY{k}{return}\PY{p}{(}\PY{n}{sk}\PY{o}{.}\PY{n}{transform}\PY{o}{.}\PY{n}{rotate}\PY{p}{(}\PY{n}{image\PYZus{}array}\PY{p}{,} \PY{n}{random\PYZus{}degree}\PY{p}{)}\PY{p}{)}
         
         \PY{k}{def} \PY{n+nf}{random\PYZus{}rotation\PYZus{}90}\PY{p}{(}\PY{n}{image\PYZus{}array}\PY{p}{:} \PY{n}{ndarray}\PY{p}{)}\PY{p}{:}
             \PY{c+c1}{\PYZsh{} randomly rotate image of 90 degrees either to the left or to the right}
             \PY{n}{random\PYZus{}degree} \PY{o}{=} \PY{n}{random}\PY{o}{.}\PY{n}{choice}\PY{p}{(}\PY{p}{[}\PY{o}{\PYZhy{}}\PY{l+m+mi}{90}\PY{p}{,} \PY{l+m+mi}{90}\PY{p}{]}\PY{p}{)}
             \PY{k}{return}\PY{p}{(}\PY{n}{sk}\PY{o}{.}\PY{n}{transform}\PY{o}{.}\PY{n}{rotate}\PY{p}{(}\PY{n}{image\PYZus{}array}\PY{p}{,} \PY{n}{random\PYZus{}degree}\PY{p}{)}\PY{p}{)}
         
         \PY{k}{def} \PY{n+nf}{random\PYZus{}noise}\PY{p}{(}\PY{n}{image\PYZus{}array}\PY{p}{:} \PY{n}{ndarray}\PY{p}{)}\PY{p}{:}
             \PY{c+c1}{\PYZsh{} add random noise to the image}
             \PY{k}{return}\PY{p}{(}\PY{n}{sk}\PY{o}{.}\PY{n}{util}\PY{o}{.}\PY{n}{random\PYZus{}noise}\PY{p}{(}\PY{n}{image\PYZus{}array}\PY{p}{)}\PY{p}{)}
         
         \PY{k}{def} \PY{n+nf}{horizontal\PYZus{}flip}\PY{p}{(}\PY{n}{image\PYZus{}array}\PY{p}{:} \PY{n}{ndarray}\PY{p}{)}\PY{p}{:}
             \PY{c+c1}{\PYZsh{} horizontal flip}
             \PY{k}{return}\PY{p}{(}\PY{n}{image\PYZus{}array}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{p}{:}\PY{p}{:}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}
         
         \PY{k}{def} \PY{n+nf}{vertical\PYZus{}flip}\PY{p}{(}\PY{n}{image\PYZus{}array}\PY{p}{:} \PY{n}{ndarray}\PY{p}{)}\PY{p}{:}
             \PY{c+c1}{\PYZsh{} vertical flip}
             \PY{k}{return}\PY{p}{(}\PY{n}{image\PYZus{}array}\PY{p}{[}\PY{p}{:}\PY{p}{:}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{p}{:}\PY{p}{]}\PY{p}{)}
         
         \PY{k}{def} \PY{n+nf}{transpose}\PY{p}{(}\PY{n}{image\PYZus{}array}\PY{p}{:} \PY{n}{ndarray}\PY{p}{)}\PY{p}{:}
         	\PY{c+c1}{\PYZsh{} transpose the image}
         	\PY{k}{return}\PY{p}{(}\PY{n}{image\PYZus{}array}\PY{p}{[}\PY{p}{:}\PY{p}{:}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{p}{:}\PY{p}{:}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}
         
         \PY{k}{def} \PY{n+nf}{zoom}\PY{p}{(}\PY{n}{image\PYZus{}array}\PY{p}{:} \PY{n}{ndarray}\PY{p}{)}\PY{p}{:}
         	\PY{c+c1}{\PYZsh{} zoom in on the image, maximum zoom: 1.4}
         	\PY{n}{dim} \PY{o}{=} \PY{n}{image\PYZus{}array}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
         	\PY{n}{zoom\PYZus{}factor} \PY{o}{=} \PY{n}{random}\PY{o}{.}\PY{n}{uniform}\PY{p}{(}\PY{l+m+mf}{1.01}\PY{p}{,} \PY{l+m+mf}{1.4}\PY{p}{)}
         	\PY{n}{zoomed\PYZus{}image} \PY{o}{=} \PY{n}{sk}\PY{o}{.}\PY{n}{transform}\PY{o}{.}\PY{n}{rescale}\PY{p}{(}\PY{n}{image\PYZus{}array}\PY{p}{,} \PY{n}{zoom\PYZus{}factor}\PY{p}{)}
         	\PY{n}{crop\PYZus{}border} \PY{o}{=} \PY{n}{floor}\PY{p}{(}\PY{p}{(}\PY{n}{zoomed\PYZus{}image}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]} \PY{o}{\PYZhy{}} \PY{n}{dim}\PY{p}{)}\PY{o}{/}\PY{l+m+mi}{2}\PY{p}{)}
         	\PY{n}{cropped\PYZus{}image} \PY{o}{=} \PY{n}{zoomed\PYZus{}image}\PY{p}{[}\PY{n}{crop\PYZus{}border} \PY{p}{:} \PY{n}{crop\PYZus{}border} \PY{o}{+} \PY{n}{dim}\PY{p}{,} \PY{n}{crop\PYZus{}border} \PY{p}{:} \PY{n}{crop\PYZus{}border} \PY{o}{+} \PY{n}{dim}\PY{p}{]}
         	\PY{k}{return}\PY{p}{(}\PY{n}{cropped\PYZus{}image}\PY{p}{)}
         
         \PY{k}{def} \PY{n+nf}{image\PYZus{}augmentation}\PY{p}{(}\PY{n}{image\PYZus{}dirs}\PY{p}{,} \PY{n}{fold}\PY{p}{)}\PY{p}{:}
         	\PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
         \PY{l+s+sd}{	this function will augment selected images and return it as a vector}
         \PY{l+s+sd}{	\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}}
         \PY{l+s+sd}{	image\PYZus{}dirs: list of dirs to the images to transform}
         \PY{l+s+sd}{	fold: the number of times the data is augmented, max = 8}
         \PY{l+s+sd}{	\PYZdq{}\PYZdq{}\PYZdq{}}
         
         	\PY{c+c1}{\PYZsh{} check if fold limits are respected}
         	\PY{k}{if} \PY{n}{fold} \PY{o}{\PYZgt{}} \PY{l+m+mi}{8} \PY{o+ow}{or} \PY{n}{fold} \PY{o}{\PYZlt{}} \PY{l+m+mi}{1}\PY{p}{:}
         		\PY{k}{return}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{fold has to be between 1 and 8}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         
         	\PY{c+c1}{\PYZsh{} convert it to an integer in case where a float was received}
         	\PY{n}{fold} \PY{o}{=} \PY{n+nb}{int}\PY{p}{(}\PY{n}{fold}\PY{p}{)}
         
         	\PY{c+c1}{\PYZsh{} establish all the functions to use for augmentation}
         	\PY{n}{function\PYZus{}list} \PY{o}{=} \PY{p}{[}\PY{n}{random\PYZus{}rotation\PYZus{}25}\PY{p}{,} \PY{n}{random\PYZus{}rotation\PYZus{}75}\PY{p}{,} \PY{n}{random\PYZus{}rotation\PYZus{}90}\PY{p}{,} \PY{n}{random\PYZus{}noise}\PY{p}{,} \PY{n}{horizontal\PYZus{}flip}\PY{p}{,} \PY{n}{vertical\PYZus{}flip}\PY{p}{,} \PY{n}{transpose}\PY{p}{,} \PY{n}{zoom}\PY{p}{]}
         
         	\PY{c+c1}{\PYZsh{} randomly choose which augmentations to use:}
         	\PY{n}{augmentations\PYZus{}to\PYZus{}use} \PY{o}{=} \PY{n}{random}\PY{o}{.}\PY{n}{sample}\PY{p}{(}\PY{n}{function\PYZus{}list}\PY{p}{,} \PY{n}{fold}\PY{p}{)}
         
         	\PY{c+c1}{\PYZsh{} print augmentation functions to use}
         	\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{the functions to be used for augmentation are: }\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         	\PY{k}{for} \PY{n}{i}\PY{p}{,} \PY{n}{fun} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{augmentations\PYZus{}to\PYZus{}use}\PY{p}{)}\PY{p}{:}
         		\PY{n+nb}{print}\PY{p}{(}\PY{n}{i}\PY{o}{+}\PY{l+m+mi}{1}\PY{p}{,} \PY{n+nb}{str}\PY{p}{(}\PY{n}{fun}\PY{p}{)}\PY{o}{.}\PY{n}{split}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ }\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}
         
         	\PY{c+c1}{\PYZsh{} create a list to store results}
         	\PY{n}{augmented} \PY{o}{=} \PY{p}{[}\PY{p}{]}
         
         	\PY{c+c1}{\PYZsh{} now we augment:}
         	\PY{k}{for} \PY{n}{img\PYZus{}dir} \PY{o+ow}{in} \PY{n}{tqdm}\PY{p}{(}\PY{n}{image\PYZus{}dirs}\PY{p}{)}\PY{p}{:}
         		\PY{c+c1}{\PYZsh{} first we read the images}
         		\PY{n}{img} \PY{o}{=} \PY{n}{cv2}\PY{o}{.}\PY{n}{imread}\PY{p}{(}\PY{n}{img\PYZus{}dir}\PY{p}{)}
         		\PY{n}{b}\PY{p}{,} \PY{n}{g}\PY{p}{,} \PY{n}{r} \PY{o}{=} \PY{n}{cv2}\PY{o}{.}\PY{n}{split}\PY{p}{(}\PY{n}{img}\PY{p}{)}
         		\PY{n}{rgb\PYZus{}img} \PY{o}{=} \PY{n}{cv2}\PY{o}{.}\PY{n}{merge}\PY{p}{(}\PY{p}{[}\PY{n}{r}\PY{p}{,} \PY{n}{g}\PY{p}{,} \PY{n}{b}\PY{p}{]}\PY{p}{)}
         
         		\PY{c+c1}{\PYZsh{} augment the image}
         		\PY{k}{for} \PY{n}{aug} \PY{o+ow}{in} \PY{n}{augmentations\PYZus{}to\PYZus{}use}\PY{p}{:}
         			\PY{n}{aug\PYZus{}img} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{aug}\PY{p}{(}\PY{n}{rgb\PYZus{}img}\PY{p}{)}\PY{p}{)}
         			\PY{n}{aug\PYZus{}img}\PY{o}{.}\PY{n}{shape} \PY{o}{=} \PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{3}\PY{o}{*}\PY{l+m+mi}{28}\PY{o}{*}\PY{l+m+mi}{28}\PY{p}{)}
         			\PY{n}{augmented}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{aug\PYZus{}img}\PY{p}{)}
         
         	\PY{c+c1}{\PYZsh{} convert to a nparray}
         	\PY{n}{augmented} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{concatenate}\PY{p}{(}\PY{n}{augmented}\PY{p}{,} \PY{n}{axis} \PY{o}{=} \PY{l+m+mi}{0}\PY{p}{)}
         
         	\PY{k}{return}\PY{p}{(}\PY{n}{augmented}\PY{p}{)}
\end{Verbatim}


    \subsubsection{7.2 custom\_dset\_alt.py}\label{custom_dset_alt.py}

contains custom dataset class as well as a function to split our image
dataset into train, validation and test subsets

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{k+kn}{import} \PY{n+nn}{os}
        \PY{k+kn}{import} \PY{n+nn}{torch}
        \PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k}{as} \PY{n+nn}{pd}
        \PY{k+kn}{from} \PY{n+nn}{skimage} \PY{k}{import} \PY{n}{io}\PY{p}{,} \PY{n}{transform}
        \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
        \PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
        \PY{k+kn}{from} \PY{n+nn}{torch}\PY{n+nn}{.}\PY{n+nn}{utils}\PY{n+nn}{.}\PY{n+nn}{data} \PY{k}{import} \PY{n}{Dataset}\PY{p}{,} \PY{n}{DataLoader}
        \PY{k+kn}{import} \PY{n+nn}{torch}\PY{n+nn}{.}\PY{n+nn}{nn} \PY{k}{as} \PY{n+nn}{nn}
        \PY{k+kn}{from} \PY{n+nn}{torchvision} \PY{k}{import} \PY{n}{models}\PY{p}{,} \PY{n}{transforms}\PY{p}{,} \PY{n}{utils}
        \PY{k+kn}{from} \PY{n+nn}{PIL} \PY{k}{import} \PY{n}{Image}
        \PY{k+kn}{from} \PY{n+nn}{tqdm} \PY{k}{import} \PY{n}{tqdm}
        \PY{k+kn}{from} \PY{n+nn}{torch}\PY{n+nn}{.}\PY{n+nn}{optim} \PY{k}{import} \PY{n}{Adam}
        \PY{k+kn}{import} \PY{n+nn}{math}
        
        
        \PY{k}{def} \PY{n+nf}{train\PYZus{}val\PYZus{}test\PYZus{}split}\PY{p}{(}\PY{n}{data\PYZus{}dir}\PY{p}{,} \PY{n}{train\PYZus{}split}\PY{p}{,} \PY{n}{val\PYZus{}split}\PY{p}{,} \PY{n}{test\PYZus{}split}\PY{p}{)}\PY{p}{:}
            \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
        \PY{l+s+sd}{    Split data set into training, validation, and test sets.}
        \PY{l+s+sd}{    data\PYZus{}dir : path to images folder}
        \PY{l+s+sd}{    train\PYZus{}split : proportion of the data to be used for training}
        \PY{l+s+sd}{    val\PYZus{}split : proportion of the data to be used for validation}
        \PY{l+s+sd}{    test\PYZus{}split : proportion of the data to be used for testing}
        \PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
        
            \PY{c+c1}{\PYZsh{} getting the sub folders and getting rid off irrelevant readings}
            \PY{n}{sub\PYZus{}paths} \PY{o}{=} \PY{p}{[}\PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{join}\PY{p}{(}\PY{n}{data\PYZus{}dir}\PY{p}{,} \PY{n}{file\PYZus{}dir}\PY{p}{)} \PY{k}{for} \PY{n}{file\PYZus{}dir} \PY{o+ow}{in} \PY{n}{os}\PY{o}{.}\PY{n}{listdir}\PY{p}{(}\PY{n}{data\PYZus{}dir}\PY{p}{)}\PY{p}{]}
            \PY{n}{sub\PYZus{}paths} \PY{o}{=} \PY{p}{[}\PY{n}{path} \PY{k}{for} \PY{n}{path} \PY{o+ow}{in} \PY{n}{sub\PYZus{}paths} \PY{k}{if} \PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{isdir}\PY{p}{(}\PY{n}{path}\PY{p}{)}\PY{p}{]}
        
            \PY{c+c1}{\PYZsh{} creating a dict to convert string classes into integers that can be converted to tensors}
            \PY{n}{class\PYZus{}dict} \PY{o}{=} \PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{water}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{trees}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{road}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{l+m+mi}{2}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{barren\PYZus{}land}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mi}{3}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{building}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mi}{4}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{grassland}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{l+m+mi}{5}\PY{p}{\PYZcb{}}
        
            \PY{c+c1}{\PYZsh{} creating a dict for all files stored in the different class specific folders}
            \PY{c+c1}{\PYZsh{} the dict contains key\PYZhy{}value pairs of the form: full\PYZus{}file\PYZus{}dir: class}
            \PY{n}{all\PYZus{}files\PYZus{}dict} \PY{o}{=} \PY{p}{\PYZob{}}\PY{p}{\PYZcb{}}
            \PY{k}{for} \PY{n}{path} \PY{o+ow}{in} \PY{n}{sub\PYZus{}paths}\PY{p}{:}
                \PY{n}{all\PYZus{}files\PYZus{}dict} \PY{o}{=} \PY{p}{\PYZob{}}\PY{o}{*}\PY{o}{*}\PY{n}{all\PYZus{}files\PYZus{}dict}\PY{p}{,} \PY{o}{*}\PY{o}{*}\PY{p}{\PYZob{}}\PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{join}\PY{p}{(}\PY{n}{path}\PY{p}{,} \PY{n}{file\PYZus{}name}\PY{p}{)}\PY{p}{:}\PY{n}{class\PYZus{}dict}\PY{p}{[}\PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{split}\PY{p}{(}\PY{n}{path}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{]} \PY{k}{for} \PY{n}{file\PYZus{}name} \PY{o+ow}{in} \PY{n}{os}\PY{o}{.}\PY{n}{listdir}\PY{p}{(}\PY{n}{path}\PY{p}{)}\PY{p}{\PYZcb{}}\PY{p}{\PYZcb{}}
        
            \PY{c+c1}{\PYZsh{} now sample according to the proportions}
            \PY{c+c1}{\PYZsh{} Size of data set}
            \PY{n}{N} \PY{o}{=} \PY{n+nb}{len}\PY{p}{(}\PY{n}{all\PYZus{}files\PYZus{}dict}\PY{p}{)}
            
            \PY{c+c1}{\PYZsh{} Size of train set}
            \PY{n}{train\PYZus{}size} \PY{o}{=} \PY{n}{math}\PY{o}{.}\PY{n}{floor}\PY{p}{(}\PY{n}{train\PYZus{}split} \PY{o}{*} \PY{n}{N}\PY{p}{)}
            
            \PY{c+c1}{\PYZsh{} Size of validation set}
            \PY{n}{val\PYZus{}size} \PY{o}{=} \PY{n}{math}\PY{o}{.}\PY{n}{floor}\PY{p}{(}\PY{n}{val\PYZus{}split} \PY{o}{*} \PY{n}{N}\PY{p}{)}
            
            \PY{c+c1}{\PYZsh{} List of all data indices}
            \PY{n}{indices} \PY{o}{=} \PY{n+nb}{list}\PY{p}{(}\PY{n+nb}{range}\PY{p}{(}\PY{n}{N}\PY{p}{)}\PY{p}{)}
            
            \PY{c+c1}{\PYZsh{} Random selection of indices for train set}
            \PY{n}{train\PYZus{}ids} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{choice}\PY{p}{(}\PY{n}{indices}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{n}{train\PYZus{}size}\PY{p}{,} \PY{n}{replace}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}
            \PY{n}{train\PYZus{}ids} \PY{o}{=} \PY{n+nb}{list}\PY{p}{(}\PY{n}{train\PYZus{}ids}\PY{p}{)}
            
            \PY{c+c1}{\PYZsh{} Deletion of indices used for train set}
            \PY{n}{indices} \PY{o}{=} \PY{n+nb}{list}\PY{p}{(}\PY{n+nb}{set}\PY{p}{(}\PY{n}{indices}\PY{p}{)} \PY{o}{\PYZhy{}} \PY{n+nb}{set}\PY{p}{(}\PY{n}{train\PYZus{}ids}\PY{p}{)}\PY{p}{)}
            
            \PY{c+c1}{\PYZsh{} Random selection of indices for validation set}
            \PY{n}{val\PYZus{}ids} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{choice}\PY{p}{(}\PY{n}{indices}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{n}{val\PYZus{}size}\PY{p}{,} \PY{n}{replace}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}
            \PY{n}{val\PYZus{}ids} \PY{o}{=} \PY{n+nb}{list}\PY{p}{(}\PY{n}{val\PYZus{}ids}\PY{p}{)}
            
            \PY{c+c1}{\PYZsh{} Selecting remaining indices for test set}
            \PY{n}{test\PYZus{}ids} \PY{o}{=} \PY{n+nb}{list}\PY{p}{(}\PY{n+nb}{set}\PY{p}{(}\PY{n}{indices}\PY{p}{)} \PY{o}{\PYZhy{}} \PY{n+nb}{set}\PY{p}{(}\PY{n}{val\PYZus{}ids}\PY{p}{)}\PY{p}{)}
        
            \PY{c+c1}{\PYZsh{} creating subsets in the forms of dictionaries}
            \PY{c+c1}{\PYZsh{} these dicts contain key\PYZhy{}value pairs of the form \PYZsq{}file\PYZus{}dir : class\PYZsq{}}
            \PY{n}{all\PYZus{}files} \PY{o}{=} \PY{n+nb}{sorted}\PY{p}{(}\PY{n+nb}{list}\PY{p}{(}\PY{n}{all\PYZus{}files\PYZus{}dict}\PY{o}{.}\PY{n}{keys}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{)}
            \PY{n}{train\PYZus{}files} \PY{o}{=} \PY{p}{\PYZob{}}\PY{n}{all\PYZus{}files}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{:} \PY{n}{all\PYZus{}files\PYZus{}dict}\PY{p}{[}\PY{n}{all\PYZus{}files}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{]} \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n}{train\PYZus{}ids}\PY{p}{\PYZcb{}}
            \PY{n}{val\PYZus{}files} \PY{o}{=} \PY{p}{\PYZob{}}\PY{n}{all\PYZus{}files}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{:} \PY{n}{all\PYZus{}files\PYZus{}dict}\PY{p}{[}\PY{n}{all\PYZus{}files}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{]} \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n}{val\PYZus{}ids}\PY{p}{\PYZcb{}}
            \PY{n}{test\PYZus{}files} \PY{o}{=} \PY{p}{\PYZob{}}\PY{n}{all\PYZus{}files}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{:} \PY{n}{all\PYZus{}files\PYZus{}dict}\PY{p}{[}\PY{n}{all\PYZus{}files}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{]} \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n}{test\PYZus{}ids}\PY{p}{\PYZcb{}}
        
            \PY{k}{return}\PY{p}{(}\PY{n}{train\PYZus{}files}\PY{p}{,} \PY{n}{val\PYZus{}files}\PY{p}{,} \PY{n}{test\PYZus{}files}\PY{p}{)}
        
        
        
        
        
        
        
        
        \PY{k}{class} \PY{n+nc}{custom\PYZus{}dset}\PY{p}{(}\PY{n}{Dataset}\PY{p}{)}\PY{p}{:}
            \PY{k}{def} \PY{n+nf}{\PYZus{}\PYZus{}init\PYZus{}\PYZus{}}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{data\PYZus{}files}\PY{p}{,} \PY{n}{transform}\PY{p}{)}\PY{p}{:}
                \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
        \PY{l+s+sd}{        data\PYZus{}files : one of the outputs of the train\PYZus{}val\PYZus{}test\PYZus{}split function}
        \PY{l+s+sd}{                     a dictionary containing keys of image directories and values of their respective classes}
        \PY{l+s+sd}{        transform : either \PYZsq{}train\PYZsq{} or \PYZsq{}val\PYZsq{}}
        \PY{l+s+sd}{                    indicates whether the dataset is for training or validation purposees}
        \PY{l+s+sd}{        \PYZdq{}\PYZdq{}\PYZdq{}}
        
                \PY{c+c1}{\PYZsh{} setting the all\PYZus{}file\PYZus{}dict to a class variable}
                \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{dir\PYZus{}to\PYZus{}class\PYZus{}dict} \PY{o}{=} \PY{n}{data\PYZus{}files}
        
                \PY{c+c1}{\PYZsh{} setting all file directories to a class variable}
                \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{all\PYZus{}files} \PY{o}{=} \PY{n+nb}{sorted}\PY{p}{(}\PY{n+nb}{list}\PY{p}{(}\PY{n}{data\PYZus{}files}\PY{o}{.}\PY{n}{keys}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{)}
        
                \PY{c+c1}{\PYZsh{} creating a list of all classes in the order of the all\PYZus{}files class variable}
                \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{labels} \PY{o}{=} \PY{p}{[}\PY{n}{data\PYZus{}files}\PY{p}{[}\PY{n}{key}\PY{p}{]} \PY{k}{for} \PY{n}{key} \PY{o+ow}{in} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{all\PYZus{}files}\PY{p}{]}
        
                \PY{c+c1}{\PYZsh{} setting the len variable}
                \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{len} \PY{o}{=} \PY{n+nb}{len}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{dir\PYZus{}to\PYZus{}class\PYZus{}dict}\PY{p}{)}
                
                \PY{c+c1}{\PYZsh{} setting the image transform class method}
                \PY{n}{normalize} \PY{o}{=} \PY{n}{transforms}\PY{o}{.}\PY{n}{Normalize}\PY{p}{(}\PY{n}{mean} \PY{o}{=} \PY{p}{[}\PY{l+m+mf}{0.485}\PY{p}{,} \PY{l+m+mf}{0.456}\PY{p}{,} \PY{l+m+mf}{0.406}\PY{p}{]}\PY{p}{,} \PY{n}{std} \PY{o}{=} \PY{p}{[}\PY{l+m+mf}{0.229}\PY{p}{,} \PY{l+m+mf}{0.224}\PY{p}{,} \PY{l+m+mf}{0.225}\PY{p}{]}\PY{p}{)}
                \PY{k}{if} \PY{n}{transform} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}
                    \PY{n}{transform} \PY{o}{=} \PY{n}{transforms}\PY{o}{.}\PY{n}{Compose}\PY{p}{(}\PY{p}{[}
                        \PY{n}{transforms}\PY{o}{.}\PY{n}{Resize}\PY{p}{(}\PY{l+m+mi}{299}\PY{p}{)}\PY{p}{,}
                        \PY{n}{transforms}\PY{o}{.}\PY{n}{CenterCrop}\PY{p}{(}\PY{l+m+mi}{299}\PY{p}{)}\PY{p}{,}
                        \PY{n}{transforms}\PY{o}{.}\PY{n}{ColorJitter}\PY{p}{(}\PY{n}{hue} \PY{o}{=} \PY{o}{.}\PY{l+m+mi}{05}\PY{p}{,} \PY{n}{saturation} \PY{o}{=} \PY{o}{.}\PY{l+m+mi}{05}\PY{p}{)}\PY{p}{,}
                        \PY{n}{transforms}\PY{o}{.}\PY{n}{RandomHorizontalFlip}\PY{p}{(}\PY{p}{)}\PY{p}{,}
                        \PY{n}{transforms}\PY{o}{.}\PY{n}{RandomVerticalFlip}\PY{p}{(}\PY{p}{)}\PY{p}{,}
                        \PY{n}{transforms}\PY{o}{.}\PY{n}{RandomRotation}\PY{p}{(}\PY{l+m+mi}{90}\PY{p}{,} \PY{n}{resample} \PY{o}{=} \PY{n}{Image}\PY{o}{.}\PY{n}{BILINEAR}\PY{p}{)}\PY{p}{,}
                        \PY{n}{transforms}\PY{o}{.}\PY{n}{ToTensor}\PY{p}{(}\PY{p}{)}\PY{p}{,}
                        \PY{n}{normalize}\PY{p}{,}
                        \PY{p}{]}\PY{p}{)}
                \PY{k}{elif} \PY{n}{transform} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{val}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}
                    \PY{n}{transform} \PY{o}{=} \PY{n}{transforms}\PY{o}{.}\PY{n}{Compose}\PY{p}{(}\PY{p}{[}
                        \PY{n}{transforms}\PY{o}{.}\PY{n}{Resize}\PY{p}{(}\PY{l+m+mi}{299}\PY{p}{)}\PY{p}{,}
                        \PY{n}{transforms}\PY{o}{.}\PY{n}{ToTensor}\PY{p}{(}\PY{p}{)}\PY{p}{,}
                        \PY{n}{normalize}\PY{p}{,}
                        \PY{p}{]}\PY{p}{)}
                \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{transform} \PY{o}{=} \PY{n}{transform}
        
            \PY{c+c1}{\PYZsh{} the \PYZus{}\PYZus{}len\PYZus{}\PYZus{} method}
            \PY{k}{def} \PY{n+nf}{\PYZus{}\PYZus{}len\PYZus{}\PYZus{}}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{)}\PY{p}{:}
                \PY{k}{return}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{all\PYZus{}files}\PY{p}{)}\PY{p}{)}
        
            \PY{c+c1}{\PYZsh{} the \PYZus{}\PYZus{}getitem\PYZus{}\PYZus{} method}
            \PY{k}{def} \PY{n+nf}{\PYZus{}\PYZus{}getitem\PYZus{}\PYZus{}}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{idx}\PY{p}{)}\PY{p}{:}
                \PY{n}{file\PYZus{}name} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{all\PYZus{}files}\PY{p}{[}\PY{n}{idx}\PY{p}{]}
                \PY{n}{image} \PY{o}{=} \PY{n}{Image}\PY{o}{.}\PY{n}{open}\PY{p}{(}\PY{n}{file\PYZus{}name}\PY{p}{)}
                \PY{c+c1}{\PYZsh{} the images are in .png format, which comes with an extra alpha channel}
                \PY{c+c1}{\PYZsh{} since we\PYZsq{}re using a pretrained model,the data has to be converted to 3 channels}
                \PY{n}{image} \PY{o}{=} \PY{n}{image}\PY{o}{.}\PY{n}{convert}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{RGB}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        
                \PY{k}{if} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{transform}\PY{p}{:}
                    \PY{n}{image} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{image}\PY{p}{)}
        
                \PY{n}{label} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{dir\PYZus{}to\PYZus{}class\PYZus{}dict}\PY{p}{[}\PY{n}{file\PYZus{}name}\PY{p}{]}
                \PY{n}{label\PYZus{}t} \PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{from\PYZus{}numpy}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{label}\PY{p}{)}\PY{p}{)}
                
                \PY{k}{return} \PY{p}{(}\PY{n}{image}\PY{p}{,} \PY{n}{label\PYZus{}t}\PY{p}{)}
\end{Verbatim}


    \subsubsection{7.3
pretrain\_inceptionv3\_alt.py}\label{pretrain_inceptionv3_alt.py}

class for the pretrained torch.vision inception\_v3 model

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{k+kn}{import} \PY{n+nn}{os}
        \PY{k+kn}{import} \PY{n+nn}{torch}
        \PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k}{as} \PY{n+nn}{pd}
        \PY{k+kn}{from} \PY{n+nn}{skimage} \PY{k}{import} \PY{n}{io}\PY{p}{,} \PY{n}{transform}
        \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
        \PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
        \PY{k+kn}{from} \PY{n+nn}{torch}\PY{n+nn}{.}\PY{n+nn}{utils}\PY{n+nn}{.}\PY{n+nn}{data} \PY{k}{import} \PY{n}{Dataset}\PY{p}{,} \PY{n}{DataLoader}
        \PY{k+kn}{import} \PY{n+nn}{torch}\PY{n+nn}{.}\PY{n+nn}{nn} \PY{k}{as} \PY{n+nn}{nn}
        \PY{k+kn}{from} \PY{n+nn}{torchvision} \PY{k}{import} \PY{n}{models}\PY{p}{,} \PY{n}{transforms}\PY{p}{,} \PY{n}{utils}
        \PY{k+kn}{from} \PY{n+nn}{PIL} \PY{k}{import} \PY{n}{Image}
        \PY{k+kn}{from} \PY{n+nn}{tqdm} \PY{k}{import} \PY{n}{tqdm}
        \PY{k+kn}{from} \PY{n+nn}{torch}\PY{n+nn}{.}\PY{n+nn}{optim} \PY{k}{import} \PY{n}{Adam}
        \PY{k+kn}{import} \PY{n+nn}{math}
        
        
        \PY{c+c1}{\PYZsh{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}}
        \PY{c+c1}{\PYZsh{} the pretrained inception v3 model class}
        \PY{c+c1}{\PYZsh{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}}
        
        \PY{k}{class} \PY{n+nc}{pretrained\PYZus{}inception\PYZus{}v3}\PY{p}{(}\PY{n}{nn}\PY{o}{.}\PY{n}{Module}\PY{p}{)}\PY{p}{:}
        
        	\PY{k}{def} \PY{n+nf}{\PYZus{}\PYZus{}init\PYZus{}\PYZus{}}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{num\PYZus{}class}\PY{p}{,} \PY{n}{use\PYZus{}cuda}\PY{p}{)}\PY{p}{:}
        		\PY{n+nb}{super}\PY{p}{(}\PY{n}{pretrained\PYZus{}inception\PYZus{}v3}\PY{p}{,} \PY{n+nb+bp}{self}\PY{p}{)}\PY{o}{.}\PY{n+nf+fm}{\PYZus{}\PYZus{}init\PYZus{}\PYZus{}}\PY{p}{(}\PY{p}{)}
        		\PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
        \PY{l+s+sd}{		num\PYZus{}class : the total number of classes to predict}
        \PY{l+s+sd}{		use\PYZus{}cude : if we\PYZsq{}re using the GPU to compute and optimise}
        \PY{l+s+sd}{		\PYZdq{}\PYZdq{}\PYZdq{}}
        
        		\PY{c+c1}{\PYZsh{} setting variables for if we\PYZsq{}re using the GPU, the number of output classes as well as the tensor dtype}
        		\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{use\PYZus{}cuda} \PY{o}{=} \PY{n}{use\PYZus{}cuda}
        		\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{num\PYZus{}class} \PY{o}{=} \PY{n}{num\PYZus{}class}
        		\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{dtype} \PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{cuda}\PY{o}{.}\PY{n}{FloatTensor} \PY{k}{if} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{use\PYZus{}cuda} \PY{k}{else} \PY{n}{torch}\PY{o}{.}\PY{n}{FloatTensor}
        
        		\PY{c+c1}{\PYZsh{} we\PYZsq{}re using the pretrained inceptionv3 model provided by torchvision}
        		\PY{n}{model} \PY{o}{=} \PY{n}{models}\PY{o}{.}\PY{n}{inception\PYZus{}v3}\PY{p}{(}\PY{n}{pretrained}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
        		\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{model} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{cuda}\PY{p}{(}\PY{p}{)} \PY{k}{if} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{use\PYZus{}cuda} \PY{k}{else} \PY{n}{model}
        
        		\PY{c+c1}{\PYZsh{} freeze all layer weights}
        		\PY{k}{for} \PY{n}{param} \PY{o+ow}{in} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{model}\PY{o}{.}\PY{n}{parameters}\PY{p}{(}\PY{p}{)}\PY{p}{:}
        			\PY{n}{param}\PY{o}{.}\PY{n}{requires\PYZus{}grad} \PY{o}{=} \PY{k+kc}{False}
        
        		\PY{c+c1}{\PYZsh{} modifying the classifier layer}
        		\PY{n}{num\PYZus{}features} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{model}\PY{o}{.}\PY{n}{fc}\PY{o}{.}\PY{n}{in\PYZus{}features}
        		\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{model}\PY{o}{.}\PY{n}{fc} \PY{o}{=} \PY{n}{nn}\PY{o}{.}\PY{n}{Linear}\PY{p}{(}\PY{n}{num\PYZus{}features}\PY{p}{,} \PY{n}{num\PYZus{}class}\PY{p}{)}
        
        		\PY{c+c1}{\PYZsh{} we choose to unfreeze the weights of parameters following(but not including) the Conv2d\PYZus{}4a\PYZus{}3x3 layer}
        		\PY{c+c1}{\PYZsh{} act as a testing mechanism}
        		\PY{n}{ct} \PY{o}{=} \PY{p}{[}\PY{p}{]}
        		\PY{c+c1}{\PYZsh{} loop through through the layers}
        		\PY{k}{for} \PY{n}{name}\PY{p}{,} \PY{n}{child} \PY{o+ow}{in} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{model}\PY{o}{.}\PY{n}{named\PYZus{}children}\PY{p}{(}\PY{p}{)}\PY{p}{:}
        			\PY{k}{if} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Conv2d\PYZus{}4a\PYZus{}3x3}\PY{l+s+s2}{\PYZdq{}} \PY{o+ow}{in} \PY{n}{ct}\PY{p}{:}
        				\PY{k}{for} \PY{n}{params} \PY{o+ow}{in} \PY{n}{child}\PY{o}{.}\PY{n}{parameters}\PY{p}{(}\PY{p}{)}\PY{p}{:}
        					\PY{n}{params}\PY{o}{.}\PY{n}{requires\PYZus{}grad} \PY{o}{=} \PY{k+kc}{True}
        			
        
        	\PY{k}{def} \PY{n+nf}{forward}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{inputs}\PY{p}{)}\PY{p}{:}
        		\PY{k}{return}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{model}\PY{p}{(}\PY{n}{inputs}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \subsubsection{7.4 train\_alt.py}\label{train_alt.py}

function for training the CNN

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{k+kn}{import} \PY{n+nn}{os}
        \PY{k+kn}{import} \PY{n+nn}{torch}
        \PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k}{as} \PY{n+nn}{pd}
        \PY{k+kn}{from} \PY{n+nn}{skimage} \PY{k}{import} \PY{n}{io}\PY{p}{,} \PY{n}{transform}
        \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
        \PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
        \PY{k+kn}{from} \PY{n+nn}{torch}\PY{n+nn}{.}\PY{n+nn}{utils}\PY{n+nn}{.}\PY{n+nn}{data} \PY{k}{import} \PY{n}{Dataset}\PY{p}{,} \PY{n}{DataLoader}
        \PY{k+kn}{import} \PY{n+nn}{torch}\PY{n+nn}{.}\PY{n+nn}{nn} \PY{k}{as} \PY{n+nn}{nn}
        \PY{k+kn}{from} \PY{n+nn}{torchvision} \PY{k}{import} \PY{n}{models}\PY{p}{,} \PY{n}{transforms}\PY{p}{,} \PY{n}{utils}
        \PY{k+kn}{from} \PY{n+nn}{PIL} \PY{k}{import} \PY{n}{Image}
        \PY{k+kn}{from} \PY{n+nn}{tqdm} \PY{k}{import} \PY{n}{tqdm}
        \PY{k+kn}{from} \PY{n+nn}{torch}\PY{n+nn}{.}\PY{n+nn}{optim} \PY{k}{import} \PY{n}{Adam}\PY{p}{,} \PY{n}{SGD}\PY{p}{,} \PY{n}{lr\PYZus{}scheduler}
        \PY{k+kn}{import} \PY{n+nn}{math}
        \PY{k+kn}{from} \PY{n+nn}{torch}\PY{n+nn}{.}\PY{n+nn}{utils}\PY{n+nn}{.}\PY{n+nn}{data} \PY{k}{import} \PY{n}{WeightedRandomSampler}
        \PY{k+kn}{from} \PY{n+nn}{collections} \PY{k}{import} \PY{n}{Counter}
        \PY{k+kn}{import} \PY{n+nn}{time}
        \PY{k+kn}{from} \PY{n+nn}{pretrained\PYZus{}inceptionv3\PYZus{}alt} \PY{k}{import} \PY{n}{pretrained\PYZus{}inception\PYZus{}v3}
        \PY{k+kn}{from} \PY{n+nn}{custom\PYZus{}dset\PYZus{}new\PYZus{}alt} \PY{k}{import} \PY{n}{custom\PYZus{}dset}\PY{p}{,} \PY{n}{train\PYZus{}val\PYZus{}test\PYZus{}split}
        \PY{k+kn}{import} \PY{n+nn}{pickle}
        
        
        \PY{k}{def} \PY{n+nf}{train}\PY{p}{(}\PY{n}{data\PYZus{}dir}\PY{p}{,} \PY{n}{save\PYZus{}dir}\PY{p}{,} \PY{n}{num\PYZus{}class}\PY{p}{,} \PY{n}{num\PYZus{}epoch} \PY{o}{=} \PY{l+m+mi}{20}\PY{p}{,}\PYZbs{}
        	\PY{n}{bs} \PY{o}{=} \PY{l+m+mi}{4}\PY{p}{,} \PY{n}{lr} \PY{o}{=} \PY{l+m+mf}{1e\PYZhy{}3}\PY{p}{,} \PY{n}{use\PYZus{}cuda} \PY{o}{=} \PY{k+kc}{False}\PY{p}{,} \PY{n}{num\PYZus{}workers} \PY{o}{=} \PY{l+m+mi}{1}\PY{p}{,}\PYZbs{}
        	\PY{n}{name} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{model}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{train\PYZus{}prop} \PY{o}{=} \PY{l+m+mf}{0.7}\PY{p}{,} \PY{n}{val\PYZus{}prop} \PY{o}{=} \PY{l+m+mf}{0.2}\PY{p}{,}
        	\PY{n}{step\PYZus{}size} \PY{o}{=} \PY{l+m+mi}{4}\PY{p}{,} \PY{n}{gamma} \PY{o}{=} \PY{l+m+mf}{0.1}\PY{p}{)}\PY{p}{:}
        	\PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
        \PY{l+s+sd}{	params:}
        \PY{l+s+sd}{	data\PYZus{}dir: where the image folder is stored}
        \PY{l+s+sd}{	save\PYZus{}dir: where the model should be saved after/during training}
        \PY{l+s+sd}{	number\PYZus{}class: the number of classes to predict}
        \PY{l+s+sd}{	num\PYZus{}epoch (20 by default): the number of epochs to train}
        \PY{l+s+sd}{	bs (4 by default): the batch size}
        \PY{l+s+sd}{	lr (0.001 by default): the starting learning rate}
        \PY{l+s+sd}{	use\PYZus{}cude(false by default): boolean, wether to use the GPU}
        \PY{l+s+sd}{	num\PYZus{}workers (1 by dfault): the number of workers to use for the computation,}
        \PY{l+s+sd}{				note that if use\PYZus{}cude = True, it should be set to equal 1}
        \PY{l+s+sd}{	name (\PYZsq{}model\PYZsq{} by default): name of the model when it is saved}
        \PY{l+s+sd}{	train\PYZus{}prop (0.7 by default): the propotion of the data used for trainning}
        \PY{l+s+sd}{	val\PYZus{}prop (0.2 by default): the propotion of the data used for validation}
        \PY{l+s+sd}{	step\PYZus{}size (4 by default): the frequency for learning rate decay}
        \PY{l+s+sd}{	gamma (0.1 by default): the factor by which the learning rate decays}
        \PY{l+s+sd}{	\PYZdq{}\PYZdq{}\PYZdq{}}
        
        	\PY{c+c1}{\PYZsh{} checkpoint beginning time}
        	\PY{n}{begin} \PY{o}{=} \PY{n}{time}\PY{o}{.}\PY{n}{time}\PY{p}{(}\PY{p}{)}
        
        	\PY{c+c1}{\PYZsh{} instantiate the vgg model}
        	\PY{n}{model} \PY{o}{=} \PY{n}{pretrained\PYZus{}inception\PYZus{}v3}\PY{p}{(}\PY{n}{num\PYZus{}class}\PY{p}{,} \PY{n}{use\PYZus{}cuda}\PY{p}{)}
        
        	\PY{c+c1}{\PYZsh{} we check if the save\PYZus{}dir exists, if not, we create it}
        	\PY{k}{if} \PY{o+ow}{not} \PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{isdir}\PY{p}{(}\PY{n}{save\PYZus{}dir}\PY{p}{)}\PY{p}{:}
        		\PY{n}{os}\PY{o}{.}\PY{n}{mkdir}\PY{p}{(}\PY{n}{save\PYZus{}dir}\PY{p}{)}
        
        	\PY{c+c1}{\PYZsh{} define the model path}
        	\PY{n}{modelpath} \PY{o}{=} \PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{join}\PY{p}{(}\PY{n}{save\PYZus{}dir}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{.pt}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{name}\PY{p}{)}\PY{p}{)}
        
        	\PY{c+c1}{\PYZsh{} in the case of paused training, do we wish to continue training?}
        	\PY{k}{if} \PY{n}{use\PYZus{}cuda}\PY{p}{:}
        		\PY{n}{model} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{cuda}\PY{p}{(}\PY{p}{)}
        
        	\PY{c+c1}{\PYZsh{} setting up the loss and accuracy variables}
        	\PY{n}{loss\PYZus{}record} \PY{o}{=} \PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{np}\PY{o}{.}\PY{n}{zeros}\PY{p}{(}\PY{n}{num\PYZus{}epoch}\PY{p}{)}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{val}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{np}\PY{o}{.}\PY{n}{zeros}\PY{p}{(}\PY{n}{num\PYZus{}epoch}\PY{p}{)}\PY{p}{\PYZcb{}}
        	\PY{n}{acc\PYZus{}record} \PY{o}{=} \PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{np}\PY{o}{.}\PY{n}{zeros}\PY{p}{(}\PY{n}{num\PYZus{}epoch}\PY{p}{)}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{val}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{np}\PY{o}{.}\PY{n}{zeros}\PY{p}{(}\PY{n}{num\PYZus{}epoch}\PY{p}{)}\PY{p}{\PYZcb{}}
        
        	\PY{c+c1}{\PYZsh{} setting up the loss function and optimisation method}
        	\PY{c+c1}{\PYZsh{} we use the cross entropy for the multiclass classification task}
        	\PY{n}{loss\PYZus{}fun} \PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{nn}\PY{o}{.}\PY{n}{CrossEntropyLoss}\PY{p}{(}\PY{n}{reduction} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{sum}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        	\PY{c+c1}{\PYZsh{} we use stochastic gradient descend for optimisation}
        	\PY{n}{optim} \PY{o}{=} \PY{n}{SGD}\PY{p}{(}\PY{n}{model}\PY{o}{.}\PY{n}{parameters}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{n}{lr} \PY{o}{=} \PY{n}{lr}\PY{p}{,} \PY{n}{momentum} \PY{o}{=} \PY{l+m+mf}{0.9}\PY{p}{)}
        	\PY{c+c1}{\PYZsh{} we apply learning rate decay}
        	\PY{n}{exp\PYZus{}lr\PYZus{}scheduler} \PY{o}{=} \PY{n}{lr\PYZus{}scheduler}\PY{o}{.}\PY{n}{StepLR}\PY{p}{(}\PY{n}{optim}\PY{p}{,} \PY{n}{step\PYZus{}size} \PY{o}{=} \PY{n}{step\PYZus{}size}\PY{p}{,} \PY{n}{gamma} \PY{o}{=} \PY{n}{gamma}\PY{p}{)}
        
        	\PY{c+c1}{\PYZsh{} split the dataset into train, val and test}
        	\PY{n}{test\PYZus{}prop} \PY{o}{=} \PY{l+m+mi}{1} \PY{o}{\PYZhy{}} \PY{n}{train\PYZus{}prop} \PY{o}{\PYZhy{}} \PY{n}{val\PYZus{}prop}
        	\PY{n}{train\PYZus{}data}\PY{p}{,} \PY{n}{val\PYZus{}data}\PY{p}{,} \PY{n}{test\PYZus{}data} \PY{o}{=} \PY{n}{train\PYZus{}val\PYZus{}test\PYZus{}split}\PY{p}{(}\PY{n}{data\PYZus{}dir}\PY{p}{,} \PY{n}{train\PYZus{}prop}\PY{p}{,} \PY{n}{val\PYZus{}prop}\PY{p}{,} \PY{n}{test\PYZus{}prop}\PY{p}{)}
        
        	\PY{c+c1}{\PYZsh{} saving the test data. We save the test data first in case we want to terminate the training early}
        	\PY{k}{with} \PY{n+nb}{open}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{.pickle}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{join}\PY{p}{(}\PY{n}{save\PYZus{}dir}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{test\PYZus{}data}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{wb}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} \PY{k}{as} \PY{n}{handle}\PY{p}{:}
        		\PY{n}{pickle}\PY{o}{.}\PY{n}{dump}\PY{p}{(}\PY{n}{test\PYZus{}data}\PY{p}{,} \PY{n}{handle}\PY{p}{,} \PY{n}{protocol} \PY{o}{=} \PY{n}{pickle}\PY{o}{.}\PY{n}{HIGHEST\PYZus{}PROTOCOL}\PY{p}{)}
        
        	\PY{c+c1}{\PYZsh{} set up the datasets}
        	\PY{n}{dset} \PY{o}{=} \PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{custom\PYZus{}dset}\PY{p}{(}\PY{n}{data\PYZus{}files} \PY{o}{=} \PY{n}{train\PYZus{}data}\PY{p}{,} \PY{n}{transform} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{,}
        			\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{val}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{custom\PYZus{}dset}\PY{p}{(}\PY{n}{data\PYZus{}files} \PY{o}{=} \PY{n}{val\PYZus{}data}\PY{p}{,} \PY{n}{transform} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{val}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{\PYZcb{}}
        
        	\PY{c+c1}{\PYZsh{} setting up a random weighted sampler to ensure the classes are balanced in the training phase}
        	\PY{c+c1}{\PYZsh{} calculating weights for the dset indices according to their respective class}
        	\PY{n}{train\PYZus{}class\PYZus{}sample\PYZus{}count} \PY{o}{=} \PY{n}{Counter}\PY{p}{(}\PY{n}{dset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{labels}\PY{p}{)}
        	\PY{n}{sorted\PYZus{}train\PYZus{}class\PYZus{}sample\PYZus{}count} \PY{o}{=} \PY{p}{[}\PY{n}{train\PYZus{}class\PYZus{}sample\PYZus{}count}\PY{p}{[}\PY{n}{key}\PY{p}{]} \PY{k}{for} \PY{n}{key} \PY{o+ow}{in} \PY{n+nb}{sorted}\PY{p}{(}\PY{n}{train\PYZus{}class\PYZus{}sample\PYZus{}count}\PY{o}{.}\PY{n}{keys}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{]}
        	\PY{n}{weights} \PY{o}{=} \PY{l+m+mf}{100000.}\PY{o}{/}\PY{n}{torch}\PY{o}{.}\PY{n}{tensor}\PY{p}{(}\PY{n}{sorted\PYZus{}train\PYZus{}class\PYZus{}sample\PYZus{}count}\PY{p}{,} \PY{n}{dtype} \PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{float}\PY{p}{)}
        	\PY{n}{samples\PYZus{}weights} \PY{o}{=} \PY{p}{[}\PY{n}{weights}\PY{p}{[}\PY{n}{label}\PY{p}{]} \PY{k}{for} \PY{n}{label} \PY{o+ow}{in} \PY{n}{dset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{labels}\PY{p}{]}
        	\PY{c+c1}{\PYZsh{} the sampler}
        	\PY{n}{sampler} \PY{o}{=} \PY{n}{WeightedRandomSampler}\PY{p}{(}\PY{n}{weights}\PY{o}{=}\PY{n}{samples\PYZus{}weights}\PY{p}{,}
        									\PY{n}{num\PYZus{}samples}\PY{o}{=}\PY{n+nb}{len}\PY{p}{(}\PY{n}{samples\PYZus{}weights}\PY{p}{)}\PY{p}{,}
        									\PY{n}{replacement}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
        	\PY{c+c1}{\PYZsh{} the dataloaders, we create 2 dataloaders for the train and val phase seperately}
        	\PY{n}{dataloaders} \PY{o}{=} \PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{DataLoader}\PY{p}{(}\PY{n}{dset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{batch\PYZus{}size} \PY{o}{=} \PY{n}{bs}\PY{p}{,} \PY{n}{sampler} \PY{o}{=} \PY{n}{sampler}\PY{p}{,} \PY{n}{num\PYZus{}workers} \PY{o}{=} \PY{n}{num\PYZus{}workers}\PY{p}{,} \PY{n}{pin\PYZus{}memory} \PY{o}{=} \PY{k+kc}{False}\PY{p}{)}\PY{p}{,}
        					\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{val}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{DataLoader}\PY{p}{(}\PY{n}{dset}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{val}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{batch\PYZus{}size} \PY{o}{=} \PY{n}{bs}\PY{p}{,} \PY{n}{shuffle} \PY{o}{=} \PY{k+kc}{True}\PY{p}{,} \PY{n}{num\PYZus{}workers} \PY{o}{=} \PY{n}{num\PYZus{}workers}\PY{p}{,} \PY{n}{pin\PYZus{}memory} \PY{o}{=} \PY{k+kc}{False}\PY{p}{)}\PY{p}{\PYZcb{}}
        
        	\PY{c+c1}{\PYZsh{} create variables for storing best performing weights during training}
        	\PY{n}{best\PYZus{}model\PYZus{}wts} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{state\PYZus{}dict}\PY{p}{(}\PY{p}{)}
        	\PY{n}{best\PYZus{}acc} \PY{o}{=} \PY{l+m+mf}{0.0}
        
        	\PY{c+c1}{\PYZsh{} iterate through the training epochs}
        	\PY{k}{for} \PY{n}{epoch} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{num\PYZus{}epoch}\PY{p}{)}\PY{p}{:}
        		\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Epoch }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{/}\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{epoch}\PY{p}{,} \PY{n}{num\PYZus{}epoch} \PY{o}{\PYZhy{}} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
        		\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZhy{}}\PY{l+s+s1}{\PYZsq{}} \PY{o}{*} \PY{l+m+mi}{10}\PY{p}{)}
        
        		\PY{c+c1}{\PYZsh{} recording the running performance each epoch}
        
        		\PY{c+c1}{\PYZsh{} each epoch will have a training and validation phase}
        		\PY{k}{for} \PY{n}{phase} \PY{o+ow}{in} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{val}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{:}
        
        			\PY{c+c1}{\PYZsh{} recording the dataset size}
        			\PY{n}{running\PYZus{}loss} \PY{o}{=} \PY{l+m+mf}{0.0}
        			\PY{n}{running\PYZus{}corrects} \PY{o}{=} \PY{l+m+mi}{0}
        			\PY{n}{size} \PY{o}{=} \PY{l+m+mi}{0}
        
        			\PY{k}{if} \PY{n}{phase} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}
        				\PY{n}{exp\PYZus{}lr\PYZus{}scheduler}\PY{o}{.}\PY{n}{step}\PY{p}{(}\PY{p}{)}
        				\PY{c+c1}{\PYZsh{} setting model to trainning mode}
        				\PY{n}{model}\PY{o}{.}\PY{n}{train}\PY{p}{(}\PY{p}{)}
        			\PY{k}{else}\PY{p}{:}
        				\PY{c+c1}{\PYZsh{} setting model to validation mode}
        				\PY{n}{model}\PY{o}{.}\PY{n}{eval}\PY{p}{(}\PY{p}{)}
        
        			\PY{c+c1}{\PYZsh{} now we iterate over the data}
        			\PY{k}{for} \PY{n}{inputs}\PY{p}{,} \PY{n}{labels} \PY{o+ow}{in} \PY{n}{tqdm}\PY{p}{(}\PY{n}{dataloaders}\PY{p}{[}\PY{n}{phase}\PY{p}{]}\PY{p}{)}\PY{p}{:}
        				\PY{c+c1}{\PYZsh{} counting how many images is contained in this batch}
        				\PY{n}{batch\PYZus{}count} \PY{o}{=} \PY{n}{labels}\PY{o}{.}\PY{n}{size}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{)}
        				\PY{c+c1}{\PYZsh{} if GPU is used, cudafy inputs}
        				\PY{k}{if} \PY{n}{use\PYZus{}cuda}\PY{p}{:}
        					\PY{n}{inputs} \PY{o}{=} \PY{n}{inputs}\PY{o}{.}\PY{n}{cuda}\PY{p}{(}\PY{p}{)}
        					\PY{n}{labels} \PY{o}{=} \PY{n}{labels}\PY{o}{.}\PY{n}{cuda}\PY{p}{(}\PY{p}{)}
        
        				\PY{c+c1}{\PYZsh{} zero the parameter gradients}
        				\PY{n}{optim}\PY{o}{.}\PY{n}{zero\PYZus{}grad}\PY{p}{(}\PY{p}{)}
        
        				\PY{c+c1}{\PYZsh{} feed inputs into the model}
        				\PY{n}{output} \PY{o}{=} \PY{n}{model}\PY{p}{(}\PY{n}{inputs}\PY{p}{)}
        
        
        				\PY{c+c1}{\PYZsh{} calculate the loss and prediction performance statistics}
        				\PY{k}{if} \PY{n+nb}{type}\PY{p}{(}\PY{n}{output}\PY{p}{)} \PY{o}{==} \PY{n+nb}{tuple}\PY{p}{:}
        					\PY{n}{output}\PY{p}{,} \PY{n}{\PYZus{}} \PY{o}{=} \PY{n}{output}
        				\PY{n}{\PYZus{}}\PY{p}{,} \PY{n}{preds} \PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{max}\PY{p}{(}\PY{n}{output}\PY{o}{.}\PY{n}{data}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}
        				\PY{n}{loss} \PY{o}{=} \PY{n}{loss\PYZus{}fun}\PY{p}{(}\PY{n}{output}\PY{p}{,} \PY{n}{labels}\PY{p}{)}
        				\PY{n}{running\PYZus{}loss} \PY{o}{+}\PY{o}{=} \PY{n}{loss}
        				\PY{n}{running\PYZus{}corrects} \PY{o}{+}\PY{o}{=} \PY{n}{preds}\PY{o}{.}\PY{n}{eq}\PY{p}{(}\PY{n}{labels}\PY{o}{.}\PY{n}{view\PYZus{}as}\PY{p}{(}\PY{n}{preds}\PY{p}{)}\PY{p}{)}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)}
        
        				\PY{c+c1}{\PYZsh{} backprop and optimise if in training stage}
        				\PY{k}{if} \PY{n}{phase} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}
        					\PY{n}{loss}\PY{o}{.}\PY{n}{backward}\PY{p}{(}\PY{p}{)}
        					\PY{n}{optim}\PY{o}{.}\PY{n}{step}\PY{p}{(}\PY{p}{)}
        				
        				\PY{c+c1}{\PYZsh{} update dataset size}
        				\PY{n}{size} \PY{o}{+}\PY{o}{=} \PY{n}{batch\PYZus{}count}
        
        			\PY{n}{epoch\PYZus{}loss} \PY{o}{=} \PY{n}{running\PYZus{}loss} \PY{o}{/} \PY{n}{size}
        			\PY{n}{epoch\PYZus{}acc} \PY{o}{=} \PY{n}{running\PYZus{}corrects}\PY{o}{.}\PY{n}{item}\PY{p}{(}\PY{p}{)} \PY{o}{/} \PY{n}{size}
        
        			\PY{c+c1}{\PYZsh{} recording the historical performance}
        			\PY{n}{loss\PYZus{}record}\PY{p}{[}\PY{n}{phase}\PY{p}{]}\PY{p}{[}\PY{n}{epoch}\PY{p}{]} \PY{o}{=} \PY{n}{epoch\PYZus{}loss}
        			\PY{n}{acc\PYZus{}record}\PY{p}{[}\PY{n}{phase}\PY{p}{]}\PY{p}{[}\PY{n}{epoch}\PY{p}{]} \PY{o}{=} \PY{n}{epoch\PYZus{}acc}
        
        			\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{ loss: }\PY{l+s+si}{\PYZob{}:.4F\PYZcb{}}\PY{l+s+s1}{ Acc: }\PY{l+s+si}{\PYZob{}:.4F\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{phase}\PY{p}{,} \PY{n}{epoch\PYZus{}loss}\PY{p}{,} \PY{n}{epoch\PYZus{}acc}\PY{p}{)}\PY{p}{)}
        
        			\PY{c+c1}{\PYZsh{} deep copy and save the model if best performance}
        			\PY{k}{if} \PY{n}{phase} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{val}\PY{l+s+s1}{\PYZsq{}} \PY{o+ow}{and} \PY{n}{epoch\PYZus{}acc} \PY{o}{\PYZgt{}} \PY{n}{best\PYZus{}acc}\PY{p}{:}
        				\PY{n}{best\PYZus{}acc} \PY{o}{=} \PY{n}{epoch\PYZus{}acc}
        				\PY{n}{best\PYZus{}model\PYZus{}wts} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{state\PYZus{}dict}\PY{p}{(}\PY{p}{)}
        				\PY{n}{torch}\PY{o}{.}\PY{n}{save}\PY{p}{(}\PY{n}{model}\PY{o}{.}\PY{n}{state\PYZus{}dict}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{join}\PY{p}{(}\PY{n}{save\PYZus{}dir}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{.pt}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{name}\PY{p}{)}\PY{p}{)}\PY{p}{)}
        
        	\PY{c+c1}{\PYZsh{} saving the record performances}
        	\PY{k}{with} \PY{n+nb}{open}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{.pickle}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{join}\PY{p}{(}\PY{n}{save\PYZus{}dir}\PY{p}{,} \PY{n}{name} \PY{o}{+} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZus{}loss\PYZus{}performances}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{wb}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} \PY{k}{as} \PY{n}{handle}\PY{p}{:}
        		\PY{n}{pickle}\PY{o}{.}\PY{n}{dump}\PY{p}{(}\PY{n}{loss\PYZus{}record}\PY{p}{,} \PY{n}{handle}\PY{p}{,} \PY{n}{protocol} \PY{o}{=} \PY{n}{pickle}\PY{o}{.}\PY{n}{HIGHEST\PYZus{}PROTOCOL}\PY{p}{)}
        	\PY{k}{with} \PY{n+nb}{open}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{.pickle}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{join}\PY{p}{(}\PY{n}{save\PYZus{}dir}\PY{p}{,} \PY{n}{name} \PY{o}{+} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZus{}acc\PYZus{}performances}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{wb}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} \PY{k}{as} \PY{n}{handle}\PY{p}{:}
        		\PY{n}{pickle}\PY{o}{.}\PY{n}{dump}\PY{p}{(}\PY{n}{acc\PYZus{}record}\PY{p}{,} \PY{n}{handle}\PY{p}{,} \PY{n}{protocol} \PY{o}{=} \PY{n}{pickle}\PY{o}{.}\PY{n}{HIGHEST\PYZus{}PROTOCOL}\PY{p}{)}
        
        	\PY{c+c1}{\PYZsh{} calculating time elapsed}
        	\PY{n}{time\PYZus{}elapsed} \PY{o}{=} \PY{n}{time}\PY{o}{.}\PY{n}{time}\PY{p}{(}\PY{p}{)} \PY{o}{\PYZhy{}} \PY{n}{begin}
        	\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Training complete in }\PY{l+s+si}{\PYZob{}:.0F\PYZcb{}}\PY{l+s+s1}{m }\PY{l+s+si}{\PYZob{}:0F\PYZcb{}}\PY{l+s+s1}{s}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{time\PYZus{}elapsed} \PY{o}{/}\PY{o}{/} \PY{l+m+mi}{60}\PY{p}{,} \PY{n}{time\PYZus{}elapsed} \PY{o}{\PYZpc{}} \PY{l+m+mi}{60}\PY{p}{)}\PY{p}{)}
        	\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Best validation acc: }\PY{l+s+si}{\PYZob{}:4F\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{best\PYZus{}acc}\PY{p}{)}\PY{p}{)}
        
        	\PY{c+c1}{\PYZsh{} load the best model weights}
        	\PY{n}{model}\PY{o}{.}\PY{n}{load\PYZus{}state\PYZus{}dict}\PY{p}{(}\PY{n}{best\PYZus{}model\PYZus{}wts}\PY{p}{)}
        	\PY{k}{return}\PY{p}{(}\PY{n}{loss\PYZus{}record}\PY{p}{,} \PY{n}{acc\PYZus{}record}\PY{p}{,} \PY{n}{model}\PY{p}{,} \PY{n}{test\PYZus{}data}\PY{p}{)}
\end{Verbatim}


    \subsubsection{7.5 test\_alt.py}\label{test_alt.py}

function for testing model performance

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{k+kn}{import} \PY{n+nn}{os}
        \PY{k+kn}{import} \PY{n+nn}{torch}
        \PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k}{as} \PY{n+nn}{pd}
        \PY{k+kn}{from} \PY{n+nn}{skimage} \PY{k}{import} \PY{n}{io}\PY{p}{,} \PY{n}{transform}
        \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
        \PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
        \PY{k+kn}{from} \PY{n+nn}{torch}\PY{n+nn}{.}\PY{n+nn}{utils}\PY{n+nn}{.}\PY{n+nn}{data} \PY{k}{import} \PY{n}{Dataset}\PY{p}{,} \PY{n}{DataLoader}
        \PY{k+kn}{import} \PY{n+nn}{torch}\PY{n+nn}{.}\PY{n+nn}{nn} \PY{k}{as} \PY{n+nn}{nn}
        \PY{k+kn}{from} \PY{n+nn}{torchvision} \PY{k}{import} \PY{n}{models}\PY{p}{,} \PY{n}{transforms}\PY{p}{,} \PY{n}{utils}
        \PY{k+kn}{from} \PY{n+nn}{PIL} \PY{k}{import} \PY{n}{Image}
        \PY{k+kn}{from} \PY{n+nn}{tqdm} \PY{k}{import} \PY{n}{tqdm}
        \PY{k+kn}{from} \PY{n+nn}{torch}\PY{n+nn}{.}\PY{n+nn}{optim} \PY{k}{import} \PY{n}{Adam}\PY{p}{,} \PY{n}{SGD}\PY{p}{,} \PY{n}{lr\PYZus{}scheduler}
        \PY{k+kn}{import} \PY{n+nn}{math}
        \PY{k+kn}{from} \PY{n+nn}{torch}\PY{n+nn}{.}\PY{n+nn}{utils}\PY{n+nn}{.}\PY{n+nn}{data} \PY{k}{import} \PY{n}{WeightedRandomSampler}
        \PY{k+kn}{from} \PY{n+nn}{collections} \PY{k}{import} \PY{n}{Counter}
        \PY{k+kn}{import} \PY{n+nn}{time}
        \PY{k+kn}{from} \PY{n+nn}{pretrained\PYZus{}inceptionv3\PYZus{}alt} \PY{k}{import} \PY{n}{pretrained\PYZus{}inception\PYZus{}v3}
        \PY{k+kn}{from} \PY{n+nn}{custom\PYZus{}dset\PYZus{}new\PYZus{}alt} \PY{k}{import} \PY{n}{custom\PYZus{}dset}\PY{p}{,} \PY{n}{train\PYZus{}val\PYZus{}test\PYZus{}split}
        \PY{k+kn}{import} \PY{n+nn}{pickle}
        
        
        \PY{k}{def} \PY{n+nf}{test}\PY{p}{(}\PY{n}{model}\PY{p}{,} \PY{n}{test\PYZus{}files}\PY{p}{,} \PY{n}{bs}\PY{p}{)}\PY{p}{:}
        	\PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
        \PY{l+s+sd}{	model : the model to be tested}
        \PY{l+s+sd}{	test\PYZus{}files : the directories to the test images, output of the train\PYZus{}val\PYZus{}test\PYZus{}split function}
        \PY{l+s+sd}{	bs : batch size}
        
        \PY{l+s+sd}{	\PYZdq{}\PYZdq{}\PYZdq{}}
        
        	\PY{c+c1}{\PYZsh{} set model to eval mode}
        	\PY{n}{model}\PY{o}{.}\PY{n}{eval}\PY{p}{(}\PY{p}{)}
        
        	\PY{c+c1}{\PYZsh{} cudafy model if specified}
        	\PY{k}{if} \PY{n}{use\PYZus{}cuda}\PY{p}{:}
        		\PY{n}{model} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{cuda}\PY{p}{(}\PY{p}{)}
        
        	\PY{c+c1}{\PYZsh{} recording the running performance and the dataset size}
        	\PY{n}{running\PYZus{}loss} \PY{o}{=} \PY{l+m+mf}{0.0}
        	\PY{n}{running\PYZus{}corrects} \PY{o}{=} \PY{l+m+mi}{0}
        	\PY{n}{size} \PY{o}{=} \PY{l+m+mi}{0}
        
        	\PY{c+c1}{\PYZsh{} set up the loss function}
        	\PY{n}{loss\PYZus{}fun} \PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{nn}\PY{o}{.}\PY{n}{CrossEntropyLoss}\PY{p}{(}\PY{n}{reduction} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{sum}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        
        	\PY{c+c1}{\PYZsh{} set up the datasets}
        	\PY{n}{dset} \PY{o}{=} \PY{n}{custom\PYZus{}dset}\PY{p}{(}\PY{n}{data\PYZus{}files} \PY{o}{=} \PY{n}{test\PYZus{}files}\PY{p}{,} \PY{n}{transform} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{val}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        
        	\PY{c+c1}{\PYZsh{} set up the dataloader}
        	\PY{n}{dataloader} \PY{o}{=} \PY{n}{DataLoader}\PY{p}{(}\PY{n}{dset}\PY{p}{,} \PY{n}{batch\PYZus{}size} \PY{o}{=} \PY{n}{bs}\PY{p}{,} \PY{n}{shuffle} \PY{o}{=} \PY{k+kc}{True}\PY{p}{,} \PY{n}{num\PYZus{}workers} \PY{o}{=} \PY{l+m+mi}{1}\PY{p}{,} \PY{n}{pin\PYZus{}memory} \PY{o}{=} \PY{k+kc}{False}\PY{p}{)}
        
        	\PY{c+c1}{\PYZsh{} now iterate over the images to make predictions}
        	\PY{k}{for} \PY{n}{inputs}\PY{p}{,} \PY{n}{labels} \PY{o+ow}{in} \PY{n}{tqdm}\PY{p}{(}\PY{n}{dataloader}\PY{p}{)}\PY{p}{:}
        		\PY{c+c1}{\PYZsh{} cudafy inputs and labels if specified}
        		\PY{k}{if} \PY{n}{use\PYZus{}cuda}\PY{p}{:}
        			\PY{n}{inputs} \PY{o}{=} \PY{n}{inputs}\PY{o}{.}\PY{n}{cuda}\PY{p}{(}\PY{p}{)}
        			\PY{n}{labels} \PY{o}{=} \PY{n}{labels}\PY{o}{.}\PY{n}{cuda}\PY{p}{(}\PY{p}{)}
        		\PY{c+c1}{\PYZsh{} counting how many images is contained in this batch}
        		\PY{n}{batch\PYZus{}count} \PY{o}{=} \PY{n}{labels}\PY{o}{.}\PY{n}{size}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{)}
        		\PY{c+c1}{\PYZsh{} Forward pass}
        		\PY{n}{output} \PY{o}{=} \PY{n}{model}\PY{p}{(}\PY{n}{inputs}\PY{p}{)}
        
        		\PY{c+c1}{\PYZsh{} calculate the loss and prediction performance statistics}
        		\PY{k}{if} \PY{n+nb}{type}\PY{p}{(}\PY{n}{output}\PY{p}{)} \PY{o}{==} \PY{n+nb}{tuple}\PY{p}{:}
        			\PY{n}{output}\PY{p}{,} \PY{n}{\PYZus{}} \PY{o}{=} \PY{n}{output}
        			\PY{n}{\PYZus{}}\PY{p}{,} \PY{n}{preds} \PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{max}\PY{p}{(}\PY{n}{output}\PY{o}{.}\PY{n}{data}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}
        			\PY{n}{loss} \PY{o}{=} \PY{n}{loss\PYZus{}fun}\PY{p}{(}\PY{n}{output}\PY{p}{,} \PY{n}{labels}\PY{p}{)}
        			\PY{n}{running\PYZus{}loss} \PY{o}{+}\PY{o}{=} \PY{n}{loss}
        			\PY{n}{running\PYZus{}corrects} \PY{o}{+}\PY{o}{=} \PY{n}{preds}\PY{o}{.}\PY{n}{eq}\PY{p}{(}\PY{n}{labels}\PY{o}{.}\PY{n}{view\PYZus{}as}\PY{p}{(}\PY{n}{preds}\PY{p}{)}\PY{p}{)}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)}
        
        	
        		\PY{c+c1}{\PYZsh{} update dataset size}
        		\PY{n}{size} \PY{o}{+}\PY{o}{=} \PY{n}{batch\PYZus{}count}
        
        	\PY{c+c1}{\PYZsh{} compute the model\PYZsq{}s performance}
        	\PY{n}{model\PYZus{}loss} \PY{o}{=} \PY{n}{running\PYZus{}loss} \PY{o}{/} \PY{n}{size}
        	\PY{n}{model\PYZus{}acc} \PY{o}{=} \PY{n}{running\PYZus{}corrects} \PY{o}{/} \PY{n}{size}
        
        	\PY{k}{return}\PY{p}{(}\PY{n}{model\PYZus{}loss}\PY{p}{,} \PY{n}{model\PYZus{}acc}\PY{p}{)}
\end{Verbatim}


    \subsubsection{7.6 execute\_train\_alt.py}\label{execute_train_alt.py}

python script used for training the CNN in linux terminal with GPU

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{k+kn}{from} \PY{n+nn}{train\PYZus{}alt} \PY{k}{import} \PY{n}{train}
        \PY{k+kn}{from} \PY{n+nn}{custom\PYZus{}dset\PYZus{}new\PYZus{}alt} \PY{k}{import} \PY{n}{train\PYZus{}val\PYZus{}test\PYZus{}split}\PY{p}{,} \PY{n}{custom\PYZus{}dset}
        \PY{k+kn}{from} \PY{n+nn}{pretrained\PYZus{}inceptionv3\PYZus{}alt} \PY{k}{import} \PY{n}{pretrained\PYZus{}inception\PYZus{}v3}
        
        
        \PY{c+c1}{\PYZsh{} setting up variables}
        \PY{n}{data\PYZus{}dir} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{../../data/images/}\PY{l+s+s1}{\PYZsq{}}
        \PY{n}{save\PYZus{}dir} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{../../data/CNN\PYZus{}model\PYZus{}landtype\PYZus{}alt/}\PY{l+s+s1}{\PYZsq{}}
        \PY{n}{num\PYZus{}class} \PY{o}{=} \PY{l+m+mi}{6}
        \PY{n}{bs} \PY{o}{=} \PY{l+m+mi}{32}
        \PY{n}{name} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{model\PYZus{}alt}\PY{l+s+s1}{\PYZsq{}}
        \PY{n}{num\PYZus{}epoch} \PY{o}{=} \PY{l+m+mi}{8}
        \PY{n}{lr} \PY{o}{=} \PY{l+m+mf}{1e\PYZhy{}5}
        \PY{n}{step\PYZus{}size} \PY{o}{=} \PY{l+m+mi}{4}
        \PY{n}{gamma} \PY{o}{=} \PY{l+m+mf}{0.2}
        
        
        \PY{c+c1}{\PYZsh{} run}
        \PY{n}{loss\PYZus{}record}\PY{p}{,} \PY{n}{acc\PYZus{}record}\PY{p}{,} \PY{n}{model}\PY{p}{,} \PY{n}{test\PYZus{}data} \PY{o}{=} \PY{n}{train}\PY{p}{(}\PY{n}{data\PYZus{}dir} \PY{o}{=} \PY{n}{data\PYZus{}dir}\PY{p}{,} \PY{n}{save\PYZus{}dir} \PY{o}{=} \PY{n}{save\PYZus{}dir}\PY{p}{,} \PY{n}{num\PYZus{}class} \PY{o}{=} \PY{l+m+mi}{6}\PY{p}{,} 
        												\PY{n}{num\PYZus{}epoch} \PY{o}{=} \PY{n}{num\PYZus{}epoch}\PY{p}{,} \PY{n}{bs} \PY{o}{=} \PY{n}{bs}\PY{p}{,} \PY{n}{lr} \PY{o}{=} \PY{n}{lr}\PY{p}{,} \PY{n}{step\PYZus{}size} \PY{o}{=} \PY{n}{step\PYZus{}size}\PY{p}{,} 
        												\PY{n}{gamma} \PY{o}{=} \PY{n}{gamma}\PY{p}{,} \PY{n}{use\PYZus{}cuda} \PY{o}{=} \PY{k+kc}{True}\PY{p}{)}
\end{Verbatim}



    % Add a bibliography block to the postdoc
    
    
    
    \end{document}
