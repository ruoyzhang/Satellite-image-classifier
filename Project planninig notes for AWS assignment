Project planninig notes for AWS assignment

1. train val test split: 0.7, 0.2, 0.1.
	using val to determine if overfitting while training
	once determined and properly trained, merge val to train and train for one more epoch
	use test to finally see the performance

2. use sub/over sampling on the different classes to balance out the dataset.
	we have 6 classes and the label distribution is very very dire and we do not know the natural distribution
	see the performance first before we determine
	I think they'll want me to iterate and decide on a proper strategy before I move forward

3. 	We decided to use the inception v3 pretrained model:
	i. it's available on torchvision.models
	ii. despite having lots of layers, the number of parameters are doable (in comparison with the VGGs especially)
	We might have done this correctly, to test


4.	might need to write a custom dataset class which takes a dictionary containing k-v pairs of sub/over sampled file names and their classes because we don't seem to be able to perform resampling during the data loading stage

5.	We have A LOT of tiny images, not sure how this will fare with the weak GPU that I have
		We can probably play around the batch size to optimse for run time

6. Need to write a correct val function

7. Need to write 2 data transforms for the 2 phases: train and val

8. just test, there is clearly a problem with the weighted sampler, might need to write a new function to test out stuff, not sure how much time i will have this weekend to actually fully make this work i don't even know the basic performance of this CNN yet we need to hurry the fuck so won't be staying up late tonight car je dois me reveiller tres tot demain matin lol

9. in the meantime, we can still see what went wrong with the preds

10. Now we're training, it will take a long time to actually go through all the images. If the training does not converge soon and allow me to iterate quickly, then we're screwed, therefore we need to experiement with:
	a. multiple training with different setups simultaneously
	b. a non DL method

11. recording epoch wise performance
	Main Scheme:
				0		1		2		3		4		5		6		7		8		9		10
LOSS	train  1.2840  1.3549  1.3395  1.3741  1.3559
		val    1.0514  0.7839  0.5281  0.8342  0.9488
ACC		train  0.7436  0.7503  0.7506  0.7502  0.7510
		val    0.7809  0.8431  0.8789  0.8387  0.8190

	Main Scheme_round_2:
				0		1		2		3		4		5		6		7		8		9		10
LOSS	train  0.5449  0.5405  0.5431  0.5440  0.4543  0.4314
		val    0.3033  0.4430  0.3490  0.3081  0.4106  0.2799
ACC		train  0.8107  0.8158  0.5440  0.8173  0.8376  0.8423
		val    0.9092  0.8537  0.4543  0.8989  0.8737  0.9083


	Alt Scheme:
				0		1		2		3		4		5		6		7		8		9		10
LOSS	train  1.2970  1.3629  1.3427  1.3611  0.8111  0.6143
		val    0.6885  0.6077  0.6463  0.6243  0.4281  0.4666
ACC		train  0.7410  0.7489  0.7516  0.7503  0.7866  0.7944
		val    0.8562  0.8626  0.8618  0.8680  0.8827  0.8675



